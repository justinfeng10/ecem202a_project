# Abstract

When walking down a street, one may hear different musical instruments being played at the same time. One may wonder how to “unmix” the musical sounds into their component parts. Audio source separation is the process of separating a mixture (e.g. a pop band recording) into isolated sounds from individual sources (e.g. just the lead vocals). In this project, an environmental audio source separation model using a convolutional neural network was developed that can separate an audio mixture of up to two different audio sources at the same time (e.g. vacuum and alarm). Live audio can then be recorded through the Arduino Nano 33 BLE Sense’s on-board microphone and passed to the machine learning model for inference.

# Team

* Justin Feng
* Yang Liu

# Required Submissions

* [Proposal](proposal.md)
* [Midterm Checkpoint Presentation Slides](https://docs.google.com/presentation/d/1Vsg-iq3j5DP994vDR3WmkYU4yzW6A_noixU22QlIx8o/edit?usp=sharing)
* [Final Presentation Slides](https://docs.google.com/presentation/d/1Yf8Y32Tk36Zz1VE6MUDrayRQ5ihTwDeXtkDPviiufFo/edit?usp=sharing)
* [Final Report](report.md)
