{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C6LXMJmeS5wZ"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import tensorflow_io as tfio\n",
    "from IPython import display\n",
    "from scipy.io import wavfile\n",
    "import museval\n",
    "import json\n",
    "import glob\n",
    "import math\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Conv2DTranspose\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "QMmhpBPXS3g3"
   },
   "outputs": [],
   "source": [
    "# Grab Wav file from folder\n",
    "# Preprocessing code here and below modified from \n",
    "# Tensorflow Example: Simple Audio Recognition\n",
    "# Link: https://www.tensorflow.org/tutorials/audio/simple_audio\n",
    "def decode_audio(audio_binary):\n",
    "    audio, sr = tf.audio.decode_wav(audio_binary, desired_channels=1)\n",
    "    return tf.squeeze(audio, axis=-1), sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Y_fJGeSFTJfb"
   },
   "outputs": [],
   "source": [
    "# For a given filepath ending with a wav file, obtain the waveform and the label\n",
    "# Function for Vacuum\n",
    "def get_waveform_and_label_vacuum(file_path):\n",
    "    label = \"Vacuum Cleaner\"\n",
    "    audio_binary = tf.io.read_file(file_path)\n",
    "    waveform, sr = decode_audio(audio_binary)\n",
    "    waveform = tfio.audio.resample(waveform, 44100, 16000, name=None)\n",
    "    zeros = tf.zeros([16000,])\n",
    "    return waveform, waveform, zeros, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Ru4_jKFFTY0q"
   },
   "outputs": [],
   "source": [
    "# For a given filepath ending with a wav file, obtain the waveform and the label\n",
    "# Function for Alarm\n",
    "def get_waveform_and_label_alarm(file_path):\n",
    "    label = \"Alarm\"\n",
    "    audio_binary = tf.io.read_file(file_path)\n",
    "    waveform, sr = decode_audio(audio_binary)\n",
    "    waveform = tfio.audio.resample(waveform, 44100, 16000, name=None)\n",
    "    zeros = tf.zeros([16000,])\n",
    "    return waveform, zeros, waveform, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "KLzgwIviVadz"
   },
   "outputs": [],
   "source": [
    "# For a given filepath ending with a wav file, obtain the waveform and the label\n",
    "# Function for MIXTURE\n",
    "def get_waveform_and_label_mixture(file_path):\n",
    "    label = \"Mixture\"\n",
    "    audio_binary = tf.io.read_file(file_path)\n",
    "    waveform, sr = decode_audio(audio_binary)\n",
    "    waveform = tfio.audio.resample(waveform, 44100, 16000, name=None)\n",
    "    \n",
    "    # Obtain original files for vacuum and alarm\n",
    "    audio_binary = tf.io.read_file(file_path + \"Label/2.wav\")\n",
    "    vacuumCleanerLabel, sr = decode_audio(audio_binary)\n",
    "    vacuumCleanerLabel = tfio.audio.resample(vacuumCleanerLabel, 44100, 16000, name=None)\n",
    "    audio_binary = tf.io.read_file(file_path + \"Label/3.wav\")\n",
    "    alarmLabel, sr = decode_audio(audio_binary)\n",
    "    alarmLabel = tfio.audio.resample(alarmLabel, 44100, 16000, name=None)\n",
    "    return waveform, vacuumCleanerLabel, alarmLabel, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R9mxMMQaTgoc",
    "outputId": "5de3801c-f095-495e-c609-b306a88ab068"
   },
   "outputs": [],
   "source": [
    "# Dataset: Vacuum\n",
    "data_dir = pathlib.Path('Sounds/Esc/VacuumCleanerCut')\n",
    "filenames = tf.io.gfile.glob(str(data_dir) + '/*')\n",
    "filenames = tf.random.shuffle(filenames)\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "files_ds = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "waveformVacuum_ds = files_ds.map(get_waveform_and_label_vacuum, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    }
   ],
   "source": [
    "# Dataset: Alarm\n",
    "data_dir = pathlib.Path('Sounds/Esc/AlarmCut')\n",
    "filenames = tf.io.gfile.glob(str(data_dir) + '/*')\n",
    "filenames = tf.random.shuffle(filenames)\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "files_ds = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "waveformAlarm_ds = files_ds.map(get_waveform_and_label_alarm, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SpD1L8r0T6LX",
    "outputId": "36828f6e-0461-47fe-b479-b79b88665068"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n",
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n",
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    }
   ],
   "source": [
    "# Dataset: Mixtures\n",
    "data_dir = pathlib.Path('Sounds/Esc/MixturesBase')\n",
    "filenames = tf.io.gfile.glob(str(data_dir) + '/*1.wav')\n",
    "filenames = tf.random.shuffle(filenames)\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "files_ds = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "waveformMixture_ds = files_ds.map(get_waveform_and_label_mixture, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "lEXFNGTVtY5s"
   },
   "outputs": [],
   "source": [
    "# Add the mixture structure to the existing structure of singular wav files\n",
    "waveform_esc_ds = waveformVacuum_ds.concatenate(waveformAlarm_ds)\n",
    "waveform_esc_ds = waveform_esc_ds.concatenate(waveformMixture_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ejhBiAWpqod4",
    "outputId": "c0223746-ba9d-47ed-98d7-a7e3cec9b16f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    }
   ],
   "source": [
    "# Dataset: Vacuum\n",
    "data_dir = pathlib.Path('Sounds/Desed/Vacuum_cleanerCut')\n",
    "filenames = tf.io.gfile.glob(str(data_dir) + '/*')\n",
    "filenames = tf.random.shuffle(filenames)\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "files_ds = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "waveformVacuum_ds = files_ds.map(get_waveform_and_label_vacuum, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JNDVYluEqo-u",
    "outputId": "e0a78b2f-1194-4768-8d4d-50aacf8f8ffb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    }
   ],
   "source": [
    "# Dataset: Alarm\n",
    "data_dir = pathlib.Path('Sounds/Desed/Alarm_bell_ringingCut')\n",
    "filenames = tf.io.gfile.glob(str(data_dir) + '/*')\n",
    "filenames = tf.random.shuffle(filenames)\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "files_ds = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "waveformAlarm_ds = files_ds.map(get_waveform_and_label_alarm, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v2itRUXNqrOT",
    "outputId": "c7d1421b-c41f-4501-ca30-918397c10e83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n",
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n",
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    }
   ],
   "source": [
    "# Dataset: Mixtures\n",
    "data_dir = pathlib.Path('Sounds/Desed/MixturesBase')\n",
    "filenames = tf.io.gfile.glob(str(data_dir) + '/*1.wav')\n",
    "filenames = tf.random.shuffle(filenames)\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "files_ds = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "waveformMixture_ds = files_ds.map(get_waveform_and_label_mixture, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "bCql4BHOq2Kn"
   },
   "outputs": [],
   "source": [
    "# Add the mixture structure to the existing structure of singular wav files\n",
    "waveform_desed_ds = waveformVacuum_ds.concatenate(waveformAlarm_ds)\n",
    "waveform_desed_ds = waveform_desed_ds.concatenate(waveformMixture_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "kL6Ub1mhrA3C"
   },
   "outputs": [],
   "source": [
    "# Concatenate ESC and Desed datasets, then shuffle\n",
    "waveform_ds = waveform_esc_ds.concatenate(waveform_desed_ds)\n",
    "waveform_ds = waveform_ds.shuffle(1925, reshuffle_each_iteration=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "9-i_rHHgtqNV"
   },
   "outputs": [],
   "source": [
    "# Calculate spectrogram and return the magnitude and phase\n",
    "def get_spectrogram(waveform):\n",
    "    spectrogram = tf.signal.stft(waveform, frame_length=512, frame_step=128)\n",
    "    mag = tf.abs(spectrogram)\n",
    "    phase = tf.math.angle(spectrogram)\n",
    "    return mag, phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "HNKrES46tts9"
   },
   "outputs": [],
   "source": [
    "# Plot spectrogram, given a spectrogram and an axis\n",
    "def plot_spectrogram(spectrogram, ax):\n",
    "    # Convert to frequencies to log scale and transpose so that the time is\n",
    "    # represented in the x-axis (columns). An epsilon is added to avoid log of zero.\n",
    "    log_spec = np.log(spectrogram.T+np.finfo(float).eps)\n",
    "    height = log_spec.shape[0]\n",
    "    width = log_spec.shape[1]\n",
    "    X = np.linspace(0, np.size(spectrogram), num=width, dtype=int)\n",
    "    Y = range(height)\n",
    "    ax.pcolormesh(X, Y, log_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "NxX81BJstyHU"
   },
   "outputs": [],
   "source": [
    "# Given the raw input (audio), and the components that make up\n",
    "# the input (label1, label2), and the actual label, compute\n",
    "# the spectrograms and return the phase of the raw input\n",
    "def get_spectrogram_and_label_id(audio, label1, label2, label):\n",
    "    spectrogram, phase = get_spectrogram(audio)\n",
    "    spectrogram = tf.expand_dims(spectrogram, -1)\n",
    "    phase = tf.expand_dims(phase, -1)\n",
    "    spectrogram1, phase1 = get_spectrogram(label1)\n",
    "    spectrogram2, phase2 = get_spectrogram(label2)\n",
    "    label_id = label\n",
    "    return spectrogram, phase, spectrogram1, spectrogram2, label_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ibnE15Ljt0nf"
   },
   "outputs": [],
   "source": [
    "# Dataset: spectrograms\n",
    "spectrogram_ds = waveform_ds.map(\n",
    "    get_spectrogram_and_label_id, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "# Define train, validation, test datasets\n",
    "train_size = int(0.8*1925)\n",
    "val_size = int(0.1*1925)\n",
    "train_ds = spectrogram_ds.take(train_size)    \n",
    "val_ds = spectrogram_ds.skip(train_size).take(val_size)\n",
    "test_ds = spectrogram_ds.skip(train_size).skip(val_size)\n",
    "\n",
    "# Save test dataset\n",
    "path = \"test_dataset_base\"\n",
    "tf.data.experimental.save(test_ds, path)\n",
    "new_dataset = tf.data.experimental.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "A3Mc6HWIt75A"
   },
   "outputs": [],
   "source": [
    "# Batch the training input\n",
    "batch_size = 2\n",
    "train_ds = train_ds.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sR9Jz8Pdt9Ca"
   },
   "outputs": [],
   "source": [
    "# Source Separation ML Model\n",
    "class SourceSeparationModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(SourceSeparationModel, self).__init__()\n",
    "        # Encoder\n",
    "        self.conv1 = Conv2D(filters=30, kernel_size=(1, 257))\n",
    "        self.conv2 = Conv2D(filters=15, kernel_size=(30, 1))\n",
    "        self.d1 = Dense(units=128, activation='relu')\n",
    "        # Decoder\n",
    "        self.dClass1 = Dense(units=15, activation='relu')\n",
    "        self.dClass2 = Dense(units=15, activation='relu')\n",
    "        self.conv3Class1 = Conv2DTranspose(filters=15, kernel_size=(30, 1))\n",
    "        self.conv4Class1 = Conv2DTranspose(filters=30, kernel_size=(1, 257))\n",
    "        self.conv3Class2 = Conv2DTranspose(filters=15, kernel_size=(30, 1))\n",
    "        self.conv4Class2 = Conv2DTranspose(filters=30, kernel_size=(1, 257))\n",
    "        self.concat = Concatenate()\n",
    "        # Output\n",
    "        self.out = Dense(units=2, activation='relu')\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.d1(x)\n",
    "        out1 = self.dClass1(x)\n",
    "        out1 = self.conv3Class1(out1)\n",
    "        out1 = self.conv4Class1(out1)\n",
    "        out2 = self.dClass2(x)\n",
    "        out2 = self.conv3Class2(out2)\n",
    "        out2 = self.conv4Class2(out2)\n",
    "        output = self.concat([out1, out2])\n",
    "        return self.out(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h2OG1s9Dt-7q"
   },
   "outputs": [],
   "source": [
    "# Train Function\n",
    "def train(model, optimizer, epochs):\n",
    "    train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "    # Parameter for loss function\n",
    "    alpha = 0.001\n",
    "    for epoch in range(epochs):  \n",
    "        train_loss.reset_states()\n",
    "        for x_np, phase, spectrogram1, spectrogram2, label in train_ds:\n",
    "            with tf.GradientTape() as tape:\n",
    "                output = model(x_np, training=True)\n",
    "                # Isolate outputs\n",
    "                output1 = output[:, :, :, 0]\n",
    "                output1 = tf.expand_dims(output1, -1)\n",
    "                output2 = output[:, :, :, 1]\n",
    "                output2 = tf.expand_dims(output2, -1)\n",
    "                \n",
    "                # Compute time frequency mask\n",
    "                sum = tf.add(output1, output2)\n",
    "                filter1 = tf.math.divide_no_nan(output1, sum) \n",
    "                filter2 = tf.math.divide_no_nan(output2, sum)\n",
    "                \n",
    "                # Find predicted outputs\n",
    "                predictedOutput1 = tf.multiply(filter1, x_np)\n",
    "                predictedOutput2 = tf.multiply(filter2, x_np)\n",
    "                predictedOutput1 = tf.squeeze(predictedOutput1, axis=3)\n",
    "                predictedOutput2 = tf.squeeze(predictedOutput2, axis=3)\n",
    "\n",
    "                # Calculate Loss\n",
    "                mse = tf.keras.losses.MeanSquaredError(reduction=tf.keras.losses.Reduction.SUM)\n",
    "                loss1 = mse(predictedOutput1, spectrogram1)\n",
    "                loss2 = mse(predictedOutput2, spectrogram2)\n",
    "                alpha1 = alpha * mse(predictedOutput1, predictedOutput2)\n",
    "                alpha2 = alpha * mse(predictedOutput2, predictedOutput1)\n",
    "                lossTemp1 = tf.abs(tf.add(loss1, loss2))\n",
    "                lossTemp2 = tf.abs(tf.add(alpha1, alpha2))\n",
    "                # Subtract out differences between predicted outputs\n",
    "                loss = tf.abs(tf.subtract(lossTemp1, lossTemp2))\n",
    "\n",
    "                gradients = tape.gradient(loss, model.trainable_variables)\n",
    "                optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "                train_loss.update_state(loss)\n",
    "        \n",
    "        template = 'Epoch {}, Loss: {}'\n",
    "        print(template.format(epoch+1, train_loss.result()))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BhqZzMTxuDss",
    "outputId": "f250d671-4e3f-4712-bb78-7a1a1478725b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 549.8676147460938\n",
      "Epoch 2, Loss: 254.50755310058594\n",
      "Epoch 3, Loss: 199.46694946289062\n",
      "Epoch 4, Loss: 151.7246551513672\n",
      "Epoch 5, Loss: 145.0896759033203\n",
      "Epoch 6, Loss: 147.0858917236328\n",
      "Epoch 7, Loss: 136.55650329589844\n",
      "Epoch 8, Loss: 116.13958740234375\n",
      "Epoch 9, Loss: 115.206787109375\n",
      "Epoch 10, Loss: 117.58501434326172\n",
      "Epoch 11, Loss: 100.59513092041016\n",
      "Epoch 12, Loss: 99.49143981933594\n",
      "Epoch 13, Loss: 106.77169036865234\n",
      "Epoch 14, Loss: 97.36890411376953\n",
      "Epoch 15, Loss: 125.86157989501953\n",
      "Epoch 16, Loss: 97.06388854980469\n",
      "Epoch 17, Loss: 87.41024017333984\n",
      "Epoch 18, Loss: 85.28496551513672\n",
      "Epoch 19, Loss: 85.79940795898438\n",
      "Epoch 20, Loss: 93.31890869140625\n",
      "Model: \"source_separation_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             multiple                  7740      \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           multiple                  13515     \n",
      "                                                                 \n",
      " dense (Dense)               multiple                  2048      \n",
      "                                                                 \n",
      " dense_1 (Dense)             multiple                  1935      \n",
      "                                                                 \n",
      " dense_2 (Dense)             multiple                  1935      \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  multiple                 6765      \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  multiple                 115680    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  multiple                 6765      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_3 (Conv2DT  multiple                 115680    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " concatenate (Concatenate)   multiple                  0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             multiple                  122       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 272,185\n",
      "Trainable params: 272,185\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Instantiate model\n",
    "model = SourceSeparationModel()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001, name = \"Adam\")\n",
    "train(model, optimizer, epochs=20)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LTYhejP9OqYD",
    "outputId": "4f7c478e-54c6-46b9-9229-7ab70659f62c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/my_model_week10Check/assets\n"
     ]
    }
   ],
   "source": [
    "# Save the entire model as a SavedModel.\n",
    "!mkdir -p saved_model\n",
    "model.save('saved_model/my_model_base') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dst7QCyQOxKu",
    "outputId": "4118dbba-4bf4-4187-96d7-979cde3ce334"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"source_separation_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              multiple                  7740      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            multiple                  13515     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  2048      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  1935      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  1935      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran multiple                  6765      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr multiple                  115680    \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr multiple                  6765      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr multiple                  115680    \n",
      "_________________________________________________________________\n",
      "concatenate (Concatenate)    multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              multiple                  122       \n",
      "=================================================================\n",
      "Total params: 272,185\n",
      "Trainable params: 272,185\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load saved model\n",
    "new_model = tf.keras.models.load_model('saved_model/my_model_base', compile=False)\n",
    "# Check its architecture\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vcSDRAvg:  10.877868292682924\n",
      "vcSIRAvg:  18.674193292682926\n",
      "vcSARAvg:  17.70674865853658\n",
      "aSDRAvg:  6.91098012195122\n",
      "aSIRAvg:  14.922038658536586\n",
      "aSARAvg:  12.83725073170732\n"
     ]
    }
   ],
   "source": [
    "# Load test set\n",
    "path = \"test_dataset_base\"\n",
    "new_dataset = tf.data.experimental.load(path)\n",
    "# Initialize Metrics for different sources\n",
    "vcCSDR = 0\n",
    "vcCSIR = 0\n",
    "vcCSAR = 0\n",
    "aCSDR = 0\n",
    "aCSIR = 0\n",
    "aCSAR = 0\n",
    "sdrV = 0\n",
    "sdrA = 0\n",
    "sirV = 0\n",
    "sirA = 0\n",
    "sarV = 0\n",
    "sarA = 0\n",
    "count = 0\n",
    "for audio, phase, sound1, sound2, label in new_dataset:\n",
    "    # Pass audio into ML model and obtain predicted outputs\n",
    "    audio = tf.expand_dims(audio, axis=0)\n",
    "    output = new_model(audio)\n",
    "    output1 = output[:, :, :, 0]\n",
    "    output1 = tf.expand_dims(output1, -1)\n",
    "    output2 = output[:, :, :, 1]\n",
    "    output2 = tf.expand_dims(output2, -1)\n",
    "    sum = tf.add(output1, output2)\n",
    "    filter1 = tf.math.divide_no_nan(output1, sum) \n",
    "    filter2 = tf.math.divide_no_nan(output2, sum)\n",
    "    predictedOutput1 = tf.multiply(filter1, audio)\n",
    "    predictedOutput2 = tf.multiply(filter2, audio)\n",
    "    sound1 = tf.expand_dims(sound1, 0)\n",
    "    sound1 = tf.expand_dims(sound1, 3)\n",
    "    sound2 = tf.expand_dims(sound2, 0)\n",
    "    sound2 = tf.expand_dims(sound2, 3)\n",
    "\n",
    "    # Calculate inverse stft for inputs as well as outputs\n",
    "    magComplex = tf.cast(sound1, tf.complex64)\n",
    "    phaseComplex = tf.cast(phase, tf.complex64)\n",
    "    spectrogramx = magComplex * tf.math.exp(1j * phaseComplex)\n",
    "    spectrogramx = tf.squeeze(spectrogramx)\n",
    "    inverse_stftx0 = tf.signal.inverse_stft(spectrogramx, 512, 128)\n",
    "    inverse_stftx0 = tf.squeeze(inverse_stftx0)\n",
    "\n",
    "    magComplex = tf.cast(predictedOutput1, tf.complex64)\n",
    "    phaseComplex = tf.cast(phase, tf.complex64)\n",
    "    spectrogramx = magComplex * tf.math.exp(1j * phaseComplex)\n",
    "    spectrogramx = tf.squeeze(spectrogramx)\n",
    "    inverse_stftx1 = tf.signal.inverse_stft(spectrogramx, 512, 128)\n",
    "    inverse_stftx1 = tf.squeeze(inverse_stftx1)\n",
    "\n",
    "    magComplex = tf.cast(sound2, tf.complex64)\n",
    "    phaseComplex = tf.cast(phase, tf.complex64)\n",
    "    spectrogramx = magComplex * tf.math.exp(1j * phaseComplex)\n",
    "    spectrogramx = tf.squeeze(spectrogramx)\n",
    "    inverse_stftx2 = tf.signal.inverse_stft(spectrogramx, 512, 128)\n",
    "    inverse_stftx2 = tf.squeeze(inverse_stftx2)\n",
    "\n",
    "    magComplex = tf.cast(predictedOutput2, tf.complex64)\n",
    "    phaseComplex = tf.cast(phase, tf.complex64)\n",
    "    spectrogramx = magComplex * tf.math.exp(1j * phaseComplex)\n",
    "    spectrogramx = tf.squeeze(spectrogramx)\n",
    "    inverse_stftx3 = tf.signal.inverse_stft(spectrogramx, 512, 128)\n",
    "    inverse_stftx3 = tf.squeeze(inverse_stftx3)\n",
    "\n",
    "    # Prepare to process data\n",
    "    string = str(label.numpy())\n",
    "    length = len(string)\n",
    "    # Calculate metrics for Mixtures\n",
    "    if (string[2:length-1] == \"Mixture\"):\n",
    "        # Save inverse stfts into \"References\" and \"Estimates\" folders\n",
    "        file0 = tf.audio.encode_wav(tf.expand_dims(inverse_stftx0, 1), 16000, name=None)\n",
    "        tf.io.write_file(\"References/file0.wav\", file0, name=None)\n",
    "        file1 = tf.audio.encode_wav(tf.expand_dims(inverse_stftx1, 1), 16000, name=None)\n",
    "        tf.io.write_file(\"Estimates/file0.wav\", file1, name=None)\n",
    "\n",
    "        file2 = tf.audio.encode_wav(tf.expand_dims(inverse_stftx2, 1), 16000, name=None)\n",
    "        tf.io.write_file(\"References/file1.wav\", file2, name=None)\n",
    "        file3 = tf.audio.encode_wav(tf.expand_dims(inverse_stftx3, 1), 16000, name=None)\n",
    "        tf.io.write_file(\"Estimates/file1.wav\", file3, name=None)\n",
    "\n",
    "        # Read in saved inverse stfts\n",
    "        fs, ref0 = wavfile.read(\"References/file0.wav\")\n",
    "        fs, est0 = wavfile.read(\"Estimates/file0.wav\")\n",
    "        fs, ref1 = wavfile.read(\"References/file1.wav\")\n",
    "        fs, est1 = wavfile.read(\"Estimates/file1.wav\")\n",
    "        \n",
    "        # Error checking (code utilized from Museval)\n",
    "        if (not ((np.any(np.all(np.sum(ref0, axis=tuple(range(2, ref0.ndim))) == 0, axis=0))\n",
    "           or np.any(np.all(np.sum(est0, axis=tuple(range(2, est0.ndim))) == 0, axis=0)))\n",
    "           or (np.any(np.all(np.sum(ref1, axis=tuple(range(2, ref1.ndim))) == 0, axis=0))\n",
    "           or np.any(np.all(np.sum(est1, axis=tuple(range(2, est1.ndim))) == 0, axis=0))))):\n",
    "            \n",
    "            # Calculate scores, save in \"test.json\"\n",
    "            scores = museval.eval_dir(\"References\", \"Estimates\", \"Outputs\")\n",
    "            scores.save(\"test.json\")\n",
    "\n",
    "            # compute the metrics\n",
    "            f = open('test.json',)\n",
    "\n",
    "            # returns JSON object as\n",
    "            # a dictionary\n",
    "            data = json.load(f)\n",
    "\n",
    "            # Iterating through the json\n",
    "            # list\n",
    "            # Metrics: Vacuum\n",
    "            jsonData = data['targets'][1]['frames'][0]['metrics']\n",
    "            sdrTemp = jsonData.get('SDR')\n",
    "            sirTemp = jsonData.get('SIR')\n",
    "            sarTemp = jsonData.get('SAR')\n",
    "            if (not (math.isnan(sdrTemp))):\n",
    "                sdrV = sdrV + sdrTemp\n",
    "                vcCSDR = vcCSDR + 1\n",
    "            if (not (math.isnan(sirTemp))):\n",
    "                sirV = sirV + sirTemp\n",
    "                vcCSIR = vcCSIR + 1\n",
    "            if (not (math.isnan(sarTemp))):\n",
    "                sarV = sarV + sarTemp\n",
    "                vcCSAR = vcCSAR + 1\n",
    "\n",
    "            # Metrics: Alarm\n",
    "            jsonData = data['targets'][0]['frames'][0]['metrics']\n",
    "            sdrTemp = jsonData.get('SDR')\n",
    "            sirTemp = jsonData.get('SIR')\n",
    "            sarTemp = jsonData.get('SAR')\n",
    "            if (not (math.isnan(sdrTemp))):\n",
    "                sdrA = sdrA + sdrTemp\n",
    "                aCSDR = aCSDR + 1\n",
    "            if (not (math.isnan(sirTemp))):\n",
    "                sirA = sirA + sirTemp\n",
    "                aCSIR = aCSIR + 1\n",
    "            if (not (math.isnan(sarTemp))):\n",
    "                sarA = sarA + sarTemp\n",
    "                aCSAR = aCSAR + 1\n",
    "    # Delete files in \"References\" and \"Estimates\" folder for next interation\n",
    "    files = glob.glob('Estimates/*.wav', recursive=True)\n",
    "    for f in files:\n",
    "        try:\n",
    "            os.remove(f)\n",
    "        except OSError as e:\n",
    "            print(\"Error: %s : %s\" % (f, e.strerror))\n",
    "    files = glob.glob('References/*.wav', recursive=True)\n",
    "    for f in files:\n",
    "        try:\n",
    "            os.remove(f)\n",
    "        except OSError as e:\n",
    "            print(\"Error: %s : %s\" % (f, e.strerror))\n",
    "\n",
    "# Print out results\n",
    "vcSDRAvg = sdrV / vcCSDR\n",
    "vcSIRAvg = sirV / vcCSIR\n",
    "vcSARAvg = sarV / vcCSAR\n",
    "aSDRAvg = sdrA / aCSDR\n",
    "aSIRAvg = sirA / aCSIR\n",
    "aSARAvg = sarA / aCSAR\n",
    "print(\"vcSDRAvg: \", vcSDRAvg)\n",
    "print(\"vcSIRAvg: \", vcSIRAvg)\n",
    "print(\"vcSARAvg: \", vcSARAvg)\n",
    "print(\"aSDRAvg: \", aSDRAvg)\n",
    "print(\"aSIRAvg: \", aSIRAvg)\n",
    "print(\"aSARAvg: \", aSARAvg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Week10Check.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
