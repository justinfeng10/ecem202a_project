{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "C6LXMJmeS5wZ"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import tensorflow_io as tfio\n",
    "from IPython import display\n",
    "from scipy.io import wavfile\n",
    "import museval\n",
    "import json\n",
    "import glob\n",
    "import math\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Conv2DTranspose\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "QMmhpBPXS3g3"
   },
   "outputs": [],
   "source": [
    "# Grab Wav file from folder\n",
    "# Preprocessing code here and below modified from \n",
    "# Tensorflow Example: Simple Audio Recognition\n",
    "# Link: https://www.tensorflow.org/tutorials/audio/simple_audio\n",
    "def decode_audio(audio_binary):\n",
    "    audio, sr = tf.audio.decode_wav(audio_binary, desired_channels=1)\n",
    "    return tf.squeeze(audio, axis=-1), sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "Y_fJGeSFTJfb"
   },
   "outputs": [],
   "source": [
    "# For a given filepath ending with a wav file, obtain the waveform and the label\n",
    "# Function for Vacuum\n",
    "def get_waveform_and_label_vacuum(file_path):\n",
    "    label = \"Vacuum Cleaner\"\n",
    "    audio_binary = tf.io.read_file(file_path)\n",
    "    waveform, sr = decode_audio(audio_binary)\n",
    "    if (sr == 48000):\n",
    "      waveform = tfio.audio.resample(waveform, 48000, 16000, name=None)\n",
    "    else:\n",
    "      waveform = tfio.audio.resample(waveform, 44100, 16000, name=None)\n",
    "    zeros = tf.zeros([16000,])\n",
    "    return waveform, waveform, zeros, zeros, zeros, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "Ru4_jKFFTY0q"
   },
   "outputs": [],
   "source": [
    "# For a given filepath ending with a wav file, obtain the waveform and the label\n",
    "# Function for Alarm\n",
    "def get_waveform_and_label_alarm(file_path):\n",
    "    label = \"Alarm\"\n",
    "    audio_binary = tf.io.read_file(file_path)\n",
    "    waveform, sr = decode_audio(audio_binary)\n",
    "    if (sr == 48000):\n",
    "      waveform = tfio.audio.resample(waveform, 48000, 16000, name=None)\n",
    "    else:\n",
    "      waveform = tfio.audio.resample(waveform, 44100, 16000, name=None)\n",
    "    zeros = tf.zeros([16000,])\n",
    "    return waveform, zeros, waveform, zeros, zeros, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "cH_NkIB2b2PU"
   },
   "outputs": [],
   "source": [
    "# For a given filepath ending with a wav file, obtain the waveform and the label\n",
    "# Function for Water\n",
    "def get_waveform_and_label_water(file_path):\n",
    "    label = \"Water\"\n",
    "    audio_binary = tf.io.read_file(file_path)\n",
    "    waveform, sr = decode_audio(audio_binary)\n",
    "    waveform = tfio.audio.resample(waveform, 44100, 16000, name=None)\n",
    "    zeros = tf.zeros([16000,])\n",
    "    return waveform, zeros, zeros, waveform, zeros, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "4ZgiQuhAb2W-"
   },
   "outputs": [],
   "source": [
    "# For a given filepath ending with a wav file, obtain the waveform and the label\n",
    "# Function for Dog\n",
    "def get_waveform_and_label_dog(file_path):\n",
    "    label = \"Dog\"\n",
    "    audio_binary = tf.io.read_file(file_path)\n",
    "    waveform, sr = decode_audio(audio_binary)\n",
    "    if (sr == 48000):\n",
    "      waveform = tfio.audio.resample(waveform, 48000, 16000, name=None)\n",
    "    else:\n",
    "      waveform = tfio.audio.resample(waveform, 44100, 16000, name=None)\n",
    "    zeros = tf.zeros([16000,])\n",
    "    return waveform, zeros, zeros, zeros, waveform, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "KLzgwIviVadz"
   },
   "outputs": [],
   "source": [
    "# For a given filepath ending with a wav file, obtain the waveform and the label\n",
    "# Function for MIXTURE\n",
    "def get_waveform_and_label_mixture(file_path):\n",
    "    label = \"Mixture\"\n",
    "    audio_binary = tf.io.read_file(file_path)\n",
    "    waveform, sr = decode_audio(audio_binary)\n",
    "    if (sr == 48000):\n",
    "      waveform = tfio.audio.resample(waveform, 48000, 16000, name=None)\n",
    "    else:\n",
    "      waveform = tfio.audio.resample(waveform, 44100, 16000, name=None)\n",
    "    \n",
    "    # Obtain original files for vacuum and pouring\n",
    "    audio_binary = tf.io.read_file(file_path + \"Label/0.wav\")\n",
    "    vacuumCleanerLabel, sr = decode_audio(audio_binary)\n",
    "    if (sr == 48000):\n",
    "      vacuumCleanerLabel = tfio.audio.resample(vacuumCleanerLabel, 48000, 16000, name=None)\n",
    "    else:\n",
    "      vacuumCleanerLabel = tfio.audio.resample(vacuumCleanerLabel, 44100, 16000, name=None)\n",
    "    audio_binary = tf.io.read_file(file_path + \"Label/1.wav\")\n",
    "    alarmLabel, sr = decode_audio(audio_binary)\n",
    "    if (sr == 48000):\n",
    "      alarmLabel = tfio.audio.resample(alarmLabel, 48000, 16000, name=None)\n",
    "    else:\n",
    "      alarmLabel = tfio.audio.resample(alarmLabel, 44100, 16000, name=None)\n",
    "    audio_binary = tf.io.read_file(file_path + \"Label/2.wav\")\n",
    "    waterLabel, sr = decode_audio(audio_binary)\n",
    "    if (sr == 48000):\n",
    "      waterLabel = tfio.audio.resample(waterLabel, 48000, 16000, name=None)\n",
    "    else:\n",
    "      waterLabel = tfio.audio.resample(waterLabel, 44100, 16000, name=None)\n",
    "    audio_binary = tf.io.read_file(file_path + \"Label/3.wav\")\n",
    "    dogLabel, sr = decode_audio(audio_binary)\n",
    "    if (sr == 48000):\n",
    "      dogLabel = tfio.audio.resample(dogLabel, 48000, 16000, name=None)\n",
    "    else:\n",
    "      dogLabel = tfio.audio.resample(dogLabel, 44100, 16000, name=None)\n",
    "\n",
    "    return waveform, vacuumCleanerLabel, alarmLabel, waterLabel, dogLabel, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2967,
     "status": "ok",
     "timestamp": 1638597353698,
     "user": {
      "displayName": "Justin Feng",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14009013728782353907"
     },
     "user_tz": 480
    },
    "id": "R9mxMMQaTgoc",
    "outputId": "a7a8a34a-0abe-44ca-fb9f-07f2fd2c1c5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n",
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    }
   ],
   "source": [
    "# Dataset: Vacuum\n",
    "data_dir = pathlib.Path('Sounds/Esc/VacuumCleanerCut')\n",
    "filenames = tf.io.gfile.glob(str(data_dir) + '/*')\n",
    "filenames = tf.random.shuffle(filenames)\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "files_ds = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "waveformVacuum_ds = files_ds.map(get_waveform_and_label_vacuum, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 220,
     "status": "ok",
     "timestamp": 1638597353912,
     "user": {
      "displayName": "Justin Feng",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14009013728782353907"
     },
     "user_tz": 480
    },
    "id": "RhtKlTI8TmR4",
    "outputId": "b082e775-acd7-497c-e65c-5764c9b4d4e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n",
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    }
   ],
   "source": [
    "# Dataset: Alarm\n",
    "data_dir = pathlib.Path('Sounds/Esc/AlarmCut')\n",
    "filenames = tf.io.gfile.glob(str(data_dir) + '/*')\n",
    "filenames = tf.random.shuffle(filenames)\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "files_ds = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "waveformAlarm_ds = files_ds.map(get_waveform_and_label_alarm, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 390,
     "status": "ok",
     "timestamp": 1638597354298,
     "user": {
      "displayName": "Justin Feng",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14009013728782353907"
     },
     "user_tz": 480
    },
    "id": "maqF3GMbd5Jv",
    "outputId": "e79aa0d3-0de3-4943-fce7-403df0b31102"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    }
   ],
   "source": [
    "# Dataset: Water\n",
    "data_dir = pathlib.Path('Sounds/Esc/PouringWaterCut')\n",
    "filenames = tf.io.gfile.glob(str(data_dir) + '/*')\n",
    "filenames = tf.random.shuffle(filenames)\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "files_ds = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "waveformWater_ds = files_ds.map(get_waveform_and_label_water, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 306,
     "status": "ok",
     "timestamp": 1638597354601,
     "user": {
      "displayName": "Justin Feng",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14009013728782353907"
     },
     "user_tz": 480
    },
    "id": "4OJpfLEjeAaH",
    "outputId": "15bf95d2-8fa6-44bb-873b-21b3c594032f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n",
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    }
   ],
   "source": [
    "# Dataset: Dog\n",
    "data_dir = pathlib.Path('Sounds/Esc/DogCut')\n",
    "filenames = tf.io.gfile.glob(str(data_dir) + '/*')\n",
    "filenames = tf.random.shuffle(filenames)\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "files_ds = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "waveformDog_ds = files_ds.map(get_waveform_and_label_dog, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9034,
     "status": "ok",
     "timestamp": 1638597363632,
     "user": {
      "displayName": "Justin Feng",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14009013728782353907"
     },
     "user_tz": 480
    },
    "id": "SpD1L8r0T6LX",
    "outputId": "f423661c-fbc5-4048-b68f-316ff3e1e801"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n",
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n",
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n",
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n",
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n",
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n",
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n",
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n",
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n",
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    }
   ],
   "source": [
    "# Dataset: Mixtures\n",
    "data_dir = pathlib.Path('Sounds/Esc/MixturesVAWD')\n",
    "filenames = tf.io.gfile.glob(str(data_dir) + '/*1.wav')\n",
    "filenames = tf.random.shuffle(filenames)\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "files_ds = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "waveformMixture_ds = files_ds.map(get_waveform_and_label_mixture, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "lEXFNGTVtY5s"
   },
   "outputs": [],
   "source": [
    "# Add the mixture structure to the existing structure of singular wav files\n",
    "waveform_esc_ds = waveformVacuum_ds.concatenate(waveformAlarm_ds)\n",
    "waveform_esc_ds = waveform_esc_ds.concatenate(waveformWater_ds)\n",
    "waveform_esc_ds = waveform_esc_ds.concatenate(waveformDog_ds)\n",
    "waveform_esc_ds = waveform_esc_ds.concatenate(waveformMixture_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2145,
     "status": "ok",
     "timestamp": 1638597365773,
     "user": {
      "displayName": "Justin Feng",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14009013728782353907"
     },
     "user_tz": 480
    },
    "id": "ejhBiAWpqod4",
    "outputId": "0db984ac-b508-4c1c-f84f-3e5aed8ed974"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n",
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    }
   ],
   "source": [
    "# Dataset: Vacuum\n",
    "data_dir = pathlib.Path('Sounds/Desed/Vacuum_cleanerCut')\n",
    "filenames = tf.io.gfile.glob(str(data_dir) + '/*')\n",
    "filenames = tf.random.shuffle(filenames)\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "files_ds = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "waveformVacuum_ds = files_ds.map(get_waveform_and_label_vacuum, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1547,
     "status": "ok",
     "timestamp": 1638597367316,
     "user": {
      "displayName": "Justin Feng",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14009013728782353907"
     },
     "user_tz": 480
    },
    "id": "JNDVYluEqo-u",
    "outputId": "fb5ba839-91f0-4e31-bea9-6ea19d9142b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n",
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    }
   ],
   "source": [
    "# Dataset: Alarm\n",
    "data_dir = pathlib.Path('Sounds/Desed/Alarm_bell_ringingCut')\n",
    "filenames = tf.io.gfile.glob(str(data_dir) + '/*')\n",
    "filenames = tf.random.shuffle(filenames)\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "files_ds = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "waveformAlarm_ds = files_ds.map(get_waveform_and_label_alarm, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 212,
     "status": "ok",
     "timestamp": 1638597367525,
     "user": {
      "displayName": "Justin Feng",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14009013728782353907"
     },
     "user_tz": 480
    },
    "id": "J7ZsJTPt98yC",
    "outputId": "880ecc7b-c5a5-4903-e94b-2e7b73cc4855"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    }
   ],
   "source": [
    "# Dataset: Water\n",
    "data_dir = pathlib.Path('Sounds/Desed/Running_waterCut')\n",
    "filenames = tf.io.gfile.glob(str(data_dir) + '/*')\n",
    "filenames = tf.random.shuffle(filenames)\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "files_ds = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "waveformWater_ds = files_ds.map(get_waveform_and_label_water, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 410,
     "status": "ok",
     "timestamp": 1638597367932,
     "user": {
      "displayName": "Justin Feng",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14009013728782353907"
     },
     "user_tz": 480
    },
    "id": "PQhfnzQD-E-T",
    "outputId": "5bdfe38d-f551-4de5-9fa9-fbdd035380f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n",
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    }
   ],
   "source": [
    "# Dataset: Dog\n",
    "data_dir = pathlib.Path('Sounds/Desed/DogCut')\n",
    "filenames = tf.io.gfile.glob(str(data_dir) + '/*')\n",
    "filenames = tf.random.shuffle(filenames)\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "files_ds = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "waveformDog_ds = files_ds.map(get_waveform_and_label_dog, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7399,
     "status": "ok",
     "timestamp": 1638597375328,
     "user": {
      "displayName": "Justin Feng",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14009013728782353907"
     },
     "user_tz": 480
    },
    "id": "v2itRUXNqrOT",
    "outputId": "4c397200-5dfc-441b-b980-118bc37b8954"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n",
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n",
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n",
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n",
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n",
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n",
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n",
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n",
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n",
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    }
   ],
   "source": [
    "# Dataset: Mixtures\n",
    "data_dir = pathlib.Path('Sounds/Desed/MixturesVAWD')\n",
    "filenames = tf.io.gfile.glob(str(data_dir) + '/*1.wav')\n",
    "filenames = tf.random.shuffle(filenames)\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "files_ds = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "waveformMixture_ds = files_ds.map(get_waveform_and_label_mixture, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "bCql4BHOq2Kn"
   },
   "outputs": [],
   "source": [
    "# Add the mixture structure to the existing structure of singular wav files, then mix up wav files\n",
    "waveformVacuum_ds = waveformVacuum_ds.shuffle(345, reshuffle_each_iteration=False).take(100)\n",
    "waveformAlarm_ds = waveformAlarm_ds.shuffle(290, reshuffle_each_iteration=False).take(100)\n",
    "waveformWater_ds = waveformWater_ds.shuffle(315, reshuffle_each_iteration=False).take(100)\n",
    "waveformDog_ds = waveformDog_ds.shuffle(265, reshuffle_each_iteration=False).take(100)\n",
    "waveformMixture_ds = waveformMixture_ds.shuffle(1200, reshuffle_each_iteration=False).take(400)\n",
    "waveform_desed_ds = waveformVacuum_ds.concatenate(waveformAlarm_ds)\n",
    "waveform_desed_ds = waveform_desed_ds.concatenate(waveformWater_ds)\n",
    "waveform_desed_ds = waveform_desed_ds.concatenate(waveformDog_ds)\n",
    "waveform_desed_ds = waveform_desed_ds.concatenate(waveformMixture_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "kL6Ub1mhrA3C"
   },
   "outputs": [],
   "source": [
    "# Concatenate ESC and Desed datasets, then shuffle\n",
    "waveform_ds = waveform_esc_ds.concatenate(waveform_desed_ds)\n",
    "waveform_ds = waveform_ds.shuffle(2400, reshuffle_each_iteration=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "9-i_rHHgtqNV"
   },
   "outputs": [],
   "source": [
    "# Calculate spectrogram and return the magnitude and phase\n",
    "def get_spectrogram(waveform):\n",
    "    spectrogram = tf.signal.stft(waveform, frame_length=512, frame_step=128)\n",
    "    mag = tf.abs(spectrogram)\n",
    "    phase = tf.math.angle(spectrogram)\n",
    "    return mag, phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "HNKrES46tts9"
   },
   "outputs": [],
   "source": [
    "# Plot spectrogram, given a spectrogram and an axis\n",
    "def plot_spectrogram(spectrogram, ax):\n",
    "    # Convert to frequencies to log scale and transpose so that the time is\n",
    "    # represented in the x-axis (columns). An epsilon is added to avoid log of zero.\n",
    "    log_spec = np.log(spectrogram.T+np.finfo(float).eps)\n",
    "    height = log_spec.shape[0]\n",
    "    width = log_spec.shape[1]\n",
    "    X = np.linspace(0, np.size(spectrogram), num=width, dtype=int)\n",
    "    Y = range(height)\n",
    "    ax.pcolormesh(X, Y, log_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "NxX81BJstyHU"
   },
   "outputs": [],
   "source": [
    "# Given the raw input (audio), and the components that make up\n",
    "# the input (label0, label1, label2, label3), and the actual label, compute\n",
    "# the spectrograms and return the phase of the raw input\n",
    "def get_spectrogram_and_label_id(audio, label0, label1, label2, label3, label):\n",
    "    spectrogram, phase = get_spectrogram(audio)\n",
    "    spectrogram = tf.expand_dims(spectrogram, -1)\n",
    "    phase = tf.expand_dims(phase, -1)\n",
    "    spectrogram0, phase0 = get_spectrogram(label0)\n",
    "    spectrogram1, phase1 = get_spectrogram(label1)\n",
    "    spectrogram2, phase2 = get_spectrogram(label2)\n",
    "    spectrogram3, phase3 = get_spectrogram(label3)\n",
    "    label_id = label\n",
    "    return spectrogram, phase, spectrogram0, spectrogram1, spectrogram2, spectrogram3, label_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ibnE15Ljt0nf"
   },
   "outputs": [],
   "source": [
    "# Dataset: spectrograms\n",
    "spectrogram_ds = waveform_ds.map(\n",
    "    get_spectrogram_and_label_id, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "# Define train, validation, test datasets\n",
    "train_size = int(0.8*2400)\n",
    "val_size = int(0.1*2400)\n",
    "train_ds = spectrogram_ds.take(train_size)    \n",
    "val_ds = spectrogram_ds.skip(train_size).take(val_size)\n",
    "test_ds = spectrogram_ds.skip(train_size).skip(val_size)\n",
    "\n",
    "# Save test dataset\n",
    "path = \"test_dataset_VAWD\"\n",
    "tf.data.experimental.save(test_ds, path)\n",
    "new_dataset = tf.data.experimental.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A3Mc6HWIt75A"
   },
   "outputs": [],
   "source": [
    "# Batch the training input\n",
    "batch_size = 2\n",
    "train_ds = train_ds.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sR9Jz8Pdt9Ca"
   },
   "outputs": [],
   "source": [
    "# Source Separation ML Model\n",
    "class SourceSeparationModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(SourceSeparationModel, self).__init__()\n",
    "        # Encoder\n",
    "        self.conv1 = Conv2D(filters=30, kernel_size=(1, 257))\n",
    "        self.conv2 = Conv2D(filters=15, kernel_size=(30, 1))\n",
    "        self.d1 = Dense(units=128, activation='relu')\n",
    "        # Decoder\n",
    "        self.dClass0 = Dense(units=15, activation='relu')\n",
    "        self.dClass1 = Dense(units=15, activation='relu')\n",
    "        self.dClass2 = Dense(units=15, activation='relu')\n",
    "        self.dClass3 = Dense(units=15, activation='relu')\n",
    "        self.conv3Class0 = Conv2DTranspose(filters=15, kernel_size=(30, 1))\n",
    "        self.conv4Class0 = Conv2DTranspose(filters=30, kernel_size=(1, 257))\n",
    "        self.conv3Class1 = Conv2DTranspose(filters=15, kernel_size=(30, 1))\n",
    "        self.conv4Class1 = Conv2DTranspose(filters=30, kernel_size=(1, 257))\n",
    "        self.conv3Class2 = Conv2DTranspose(filters=15, kernel_size=(30, 1))\n",
    "        self.conv4Class2 = Conv2DTranspose(filters=30, kernel_size=(1, 257))\n",
    "        self.conv3Class3 = Conv2DTranspose(filters=15, kernel_size=(30, 1))\n",
    "        self.conv4Class3 = Conv2DTranspose(filters=30, kernel_size=(1, 257))\n",
    "        self.concat = Concatenate()\n",
    "        # Output\n",
    "        self.out = Dense(units=4, activation='relu')\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.d1(x)\n",
    "        out0 = self.dClass0(x)\n",
    "        out0 = self.conv3Class0(out0)\n",
    "        out0 = self.conv4Class0(out0)\n",
    "        out1 = self.dClass1(x)\n",
    "        out1 = self.conv3Class1(out1)\n",
    "        out1 = self.conv4Class1(out1)\n",
    "        out2 = self.dClass2(x)\n",
    "        out2 = self.conv3Class2(out2)\n",
    "        out2 = self.conv4Class2(out2)\n",
    "        out3 = self.dClass3(x)\n",
    "        out3 = self.conv3Class3(out3)\n",
    "        out3 = self.conv4Class3(out3)\n",
    "        output = self.concat([out0, out1, out2, out3])\n",
    "        return self.out(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h2OG1s9Dt-7q"
   },
   "outputs": [],
   "source": [
    "# Train Function\n",
    "def train(model, optimizer, epochs):\n",
    "    train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "    # Parameter for loss function\n",
    "    alpha = 0.001\n",
    "    for epoch in range(epochs):  \n",
    "        train_loss.reset_states()\n",
    "        for x_np, phase, spectrogram0, spectrogram1, spectrogram2, spectrogram3, label in train_ds:\n",
    "            with tf.GradientTape() as tape:\n",
    "                output = model(x_np, training=True)\n",
    "                # Isolate outputs\n",
    "                output0 = output[:, :, :, 0]\n",
    "                output0 = tf.expand_dims(output0, -1)\n",
    "                output1 = output[:, :, :, 1]\n",
    "                output1 = tf.expand_dims(output1, -1)\n",
    "                output2 = output[:, :, :, 2]\n",
    "                output2 = tf.expand_dims(output2, -1)\n",
    "                output3 = output[:, :, :, 3]\n",
    "                output3 = tf.expand_dims(output3, -1)\n",
    "                \n",
    "                # Compute time frequency mask\n",
    "                sum = tf.add(output0, output1)\n",
    "                sum = tf.add(sum, output2)\n",
    "                sum = tf.add(sum, output3)\n",
    "                filter0 = tf.math.divide_no_nan(output0, sum) \n",
    "                filter1 = tf.math.divide_no_nan(output1, sum)\n",
    "                filter2 = tf.math.divide_no_nan(output2, sum) \n",
    "                filter3 = tf.math.divide_no_nan(output3, sum)\n",
    "                \n",
    "                # Find predicted outputs\n",
    "                predictedOutput0 = tf.multiply(filter0, x_np)\n",
    "                predictedOutput1 = tf.multiply(filter1, x_np)\n",
    "                predictedOutput2 = tf.multiply(filter2, x_np)\n",
    "                predictedOutput3 = tf.multiply(filter3, x_np)\n",
    "                predictedOutput0 = tf.squeeze(predictedOutput0, axis=3)\n",
    "                predictedOutput1 = tf.squeeze(predictedOutput1, axis=3)\n",
    "                predictedOutput2 = tf.squeeze(predictedOutput2, axis=3)\n",
    "                predictedOutput3 = tf.squeeze(predictedOutput3, axis=3)\n",
    "\n",
    "                # Calculate Loss\n",
    "                mse = tf.keras.losses.MeanSquaredError(reduction=tf.keras.losses.Reduction.SUM)\n",
    "                loss0 = mse(predictedOutput0, spectrogram0)\n",
    "                loss1 = mse(predictedOutput1, spectrogram1)\n",
    "                loss2 = mse(predictedOutput2, spectrogram2)\n",
    "                loss3 = mse(predictedOutput3, spectrogram3)\n",
    "                alpha0 = alpha * mse(predictedOutput0, predictedOutput1) + alpha * mse(predictedOutput0, predictedOutput2) + alpha * mse(predictedOutput0, predictedOutput3)\n",
    "                alpha1 = alpha * mse(predictedOutput1, predictedOutput0) + alpha * mse(predictedOutput1, predictedOutput2) + alpha * mse(predictedOutput1, predictedOutput3)\n",
    "                alpha2 = alpha * mse(predictedOutput2, predictedOutput0) + alpha * mse(predictedOutput2, predictedOutput1) + alpha * mse(predictedOutput2, predictedOutput3)\n",
    "                alpha3 = alpha * mse(predictedOutput3, predictedOutput0) + alpha * mse(predictedOutput3, predictedOutput1) + alpha * mse(predictedOutput3, predictedOutput2)\n",
    "                lossTemp0 = tf.add(loss0, loss1)\n",
    "                lossTemp0 = tf.add(lossTemp0, loss2)\n",
    "                lossTemp0 = tf.add(lossTemp0, loss3)\n",
    "                lossTemp0 = tf.abs(lossTemp0)\n",
    "                lossTemp1 = tf.add(alpha0, alpha1)\n",
    "                lossTemp1 = tf.add(lossTemp1, alpha2)\n",
    "                lossTemp1 = tf.add(lossTemp1, alpha3)\n",
    "                lossTemp1 = tf.abs(lossTemp1)\n",
    "                # Subtract out differences between predicted outputs\n",
    "                loss = tf.abs(tf.subtract(lossTemp0, lossTemp1))\n",
    "                # Use original term\n",
    "                loss = lossTemp0\n",
    "\n",
    "                gradients = tape.gradient(loss, model.trainable_variables)\n",
    "                optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "                train_loss.update_state(loss)\n",
    "\n",
    "        template = 'Epoch {}, Loss: {}'\n",
    "        print(template.format(epoch+1, train_loss.result()))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6110766,
     "status": "ok",
     "timestamp": 1638607979409,
     "user": {
      "displayName": "Justin Feng",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14009013728782353907"
     },
     "user_tz": 480
    },
    "id": "BhqZzMTxuDss",
    "outputId": "058cff71-9663-4945-9666-eb7304c73844"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 454.16351318359375\n",
      "Epoch 2, Loss: 235.70172119140625\n",
      "Epoch 3, Loss: 193.24984741210938\n",
      "Epoch 4, Loss: 157.63084411621094\n",
      "Epoch 5, Loss: 142.19186401367188\n",
      "Epoch 6, Loss: 128.28878784179688\n",
      "Epoch 7, Loss: 117.70597076416016\n",
      "Epoch 8, Loss: 111.5503921508789\n",
      "Epoch 9, Loss: 174.09068298339844\n",
      "Epoch 10, Loss: 114.54934692382812\n",
      "Epoch 11, Loss: 101.30610656738281\n",
      "Epoch 12, Loss: 94.07675170898438\n",
      "Epoch 13, Loss: 92.53596496582031\n",
      "Epoch 14, Loss: 103.65042877197266\n",
      "Epoch 15, Loss: 91.07603454589844\n",
      "Epoch 16, Loss: 83.089599609375\n",
      "Epoch 17, Loss: 78.82177734375\n",
      "Epoch 18, Loss: 77.82758331298828\n",
      "Epoch 19, Loss: 73.93638610839844\n",
      "Epoch 20, Loss: 72.96896362304688\n",
      "Model: \"source_separation_model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           multiple                  7740      \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           multiple                  13515     \n",
      "                                                                 \n",
      " dense_6 (Dense)             multiple                  2048      \n",
      "                                                                 \n",
      " dense_7 (Dense)             multiple                  1935      \n",
      "                                                                 \n",
      " dense_8 (Dense)             multiple                  1935      \n",
      "                                                                 \n",
      " dense_9 (Dense)             multiple                  1935      \n",
      "                                                                 \n",
      " dense_10 (Dense)            multiple                  1935      \n",
      "                                                                 \n",
      " conv2d_transpose_8 (Conv2DT  multiple                 6765      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_9 (Conv2DT  multiple                 115680    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_10 (Conv2D  multiple                 6765      \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " conv2d_transpose_11 (Conv2D  multiple                 115680    \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " conv2d_transpose_12 (Conv2D  multiple                 6765      \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " conv2d_transpose_13 (Conv2D  multiple                 115680    \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " conv2d_transpose_14 (Conv2D  multiple                 6765      \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " conv2d_transpose_15 (Conv2D  multiple                 115680    \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " concatenate_1 (Concatenate)  multiple                 0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            multiple                  484       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 521,307\n",
      "Trainable params: 521,307\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Instantiate model\n",
    "model = SourceSeparationModel()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001, name = \"Adam\")\n",
    "train(model, optimizer, epochs=20)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4230,
     "status": "ok",
     "timestamp": 1638608244548,
     "user": {
      "displayName": "Justin Feng",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14009013728782353907"
     },
     "user_tz": 480
    },
    "id": "LTYhejP9OqYD",
    "outputId": "f5f68a5b-5824-4c9f-8eda-b62c15d4f13f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/my_model_VAWDDesedRight3/assets\n"
     ]
    }
   ],
   "source": [
    "# Save the entire model as a SavedModel.\n",
    "!mkdir -p saved_model\n",
    "model.save('saved_model/my_model_VAWD') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1922,
     "status": "ok",
     "timestamp": 1638608246459,
     "user": {
      "displayName": "Justin Feng",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14009013728782353907"
     },
     "user_tz": 480
    },
    "id": "Dst7QCyQOxKu",
    "outputId": "0f217c54-df95-4b4f-fd71-aa4b1baec1f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"source_separation_model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            multiple                  7740      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            multiple                  13515     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              multiple                  2048      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              multiple                  1935      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              multiple                  1935      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              multiple                  1935      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             multiple                  1935      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_8 (Conv2DTr multiple                  6765      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_9 (Conv2DTr multiple                  115680    \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_10 (Conv2DT multiple                  6765      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_11 (Conv2DT multiple                  115680    \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_12 (Conv2DT multiple                  6765      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_13 (Conv2DT multiple                  115680    \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_14 (Conv2DT multiple                  6765      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_15 (Conv2DT multiple                  115680    \n",
      "_________________________________________________________________\n",
      "concatenate_1 (Concatenate)  multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             multiple                  484       \n",
      "=================================================================\n",
      "Total params: 521,307\n",
      "Trainable params: 521,307\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load saved model\n",
    "new_model = tf.keras.models.load_model('saved_model/my_model_VAWD', compile=False)\n",
    "# Check its architecture\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "57jzWJZ6bjGb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vcSDRAvg:  11.354654310344833\n",
      "vcSIRAvg:  17.45233034482759\n",
      "vcSARAvg:  15.594767586206897\n",
      "aSDRAvg:  3.7343361403508784\n",
      "aSIRAvg:  13.289961052631575\n",
      "aSARAvg:  8.810929824561402\n",
      "wSDRAvg:  4.628141956521738\n",
      "wSIRAvg:  12.194360869565223\n",
      "wSARAvg:  9.379140217391301\n",
      "dSDRAvg:  4.681836842105263\n",
      "dSIRAvg:  13.064222982456146\n",
      "dSARAvg:  10.107365964912281\n"
     ]
    }
   ],
   "source": [
    "# Load test set\n",
    "path = \"test_dataset_VAWD\"\n",
    "new_dataset = tf.data.experimental.load(path)\n",
    "# Initialize Metrics for different sources\n",
    "vcCSDR = 0\n",
    "vcCSIR = 0\n",
    "vcCSAR = 0\n",
    "aCSDR = 0\n",
    "aCSIR = 0\n",
    "aCSAR = 0\n",
    "wCSDR = 0\n",
    "wCSIR = 0\n",
    "wCSAR = 0\n",
    "dCSDR = 0\n",
    "dCSIR = 0\n",
    "dCSAR = 0\n",
    "sdrV = 0\n",
    "sdrA = 0\n",
    "sdrW = 0\n",
    "sdrD = 0\n",
    "sirV = 0\n",
    "sirA = 0\n",
    "sirW = 0\n",
    "sirD = 0\n",
    "sarV = 0\n",
    "sarA = 0\n",
    "sarW = 0\n",
    "sarD = 0\n",
    "count = 0\n",
    "for audio, phase, sound0, sound1, sound2, sound3, label in new_dataset:\n",
    "    # Pass audio into ML model and obtain predicted outputs\n",
    "    audio = tf.expand_dims(audio, axis=0)\n",
    "    output = new_model(audio)\n",
    "    output0 = output[:, :, :, 0]\n",
    "    output0 = tf.expand_dims(output0, -1)\n",
    "    output1 = output[:, :, :, 1]\n",
    "    output1 = tf.expand_dims(output1, -1)\n",
    "    output2 = output[:, :, :, 2]\n",
    "    output2 = tf.expand_dims(output2, -1)\n",
    "    output3 = output[:, :, :, 3]\n",
    "    output3 = tf.expand_dims(output3, -1)\n",
    "    sum = tf.add(output0, output1)\n",
    "    sum = tf.add(sum, output2)\n",
    "    sum = tf.add(sum, output3)\n",
    "    filter0 = tf.math.divide_no_nan(output0, sum) \n",
    "    filter1 = tf.math.divide_no_nan(output1, sum)\n",
    "    filter2 = tf.math.divide_no_nan(output2, sum) \n",
    "    filter3 = tf.math.divide_no_nan(output3, sum)\n",
    "    predictedOutput0 = tf.multiply(filter0, audio)\n",
    "    predictedOutput1 = tf.multiply(filter1, audio)\n",
    "    predictedOutput2 = tf.multiply(filter2, audio)\n",
    "    predictedOutput3 = tf.multiply(filter3, audio)\n",
    "    sound0 = tf.expand_dims(sound0, 0)\n",
    "    sound0 = tf.expand_dims(sound0, 3)\n",
    "    sound1 = tf.expand_dims(sound1, 0)\n",
    "    sound1 = tf.expand_dims(sound1, 3)\n",
    "    sound2 = tf.expand_dims(sound2, 0)\n",
    "    sound2 = tf.expand_dims(sound2, 3)\n",
    "    sound3 = tf.expand_dims(sound3, 0)\n",
    "    sound3 = tf.expand_dims(sound3, 3)\n",
    "\n",
    "    # Calculate inverse stft for inputs as well as outputs\n",
    "    magComplex = tf.cast(sound0, tf.complex64)\n",
    "    phaseComplex = tf.cast(phase, tf.complex64)\n",
    "    spectrogramx = magComplex * tf.math.exp(1j * phaseComplex)\n",
    "    spectrogramx = tf.squeeze(spectrogramx)\n",
    "    inverse_stftx0 = tf.signal.inverse_stft(spectrogramx, 512, 128)\n",
    "    inverse_stftx0 = tf.squeeze(inverse_stftx0)\n",
    "\n",
    "    magComplex = tf.cast(predictedOutput0, tf.complex64)\n",
    "    phaseComplex = tf.cast(phase, tf.complex64)\n",
    "    spectrogramx = magComplex * tf.math.exp(1j * phaseComplex)\n",
    "    spectrogramx = tf.squeeze(spectrogramx)\n",
    "    inverse_stftx1 = tf.signal.inverse_stft(spectrogramx, 512, 128)\n",
    "    inverse_stftx1 = tf.squeeze(inverse_stftx1)\n",
    "\n",
    "    magComplex = tf.cast(sound1, tf.complex64)\n",
    "    phaseComplex = tf.cast(phase, tf.complex64)\n",
    "    spectrogramx = magComplex * tf.math.exp(1j * phaseComplex)\n",
    "    spectrogramx = tf.squeeze(spectrogramx)\n",
    "    inverse_stftx2 = tf.signal.inverse_stft(spectrogramx, 512, 128)\n",
    "    inverse_stftx2 = tf.squeeze(inverse_stftx2)\n",
    "\n",
    "    magComplex = tf.cast(predictedOutput1, tf.complex64)\n",
    "    phaseComplex = tf.cast(phase, tf.complex64)\n",
    "    spectrogramx = magComplex * tf.math.exp(1j * phaseComplex)\n",
    "    spectrogramx = tf.squeeze(spectrogramx)\n",
    "    inverse_stftx3 = tf.signal.inverse_stft(spectrogramx, 512, 128)\n",
    "    inverse_stftx3 = tf.squeeze(inverse_stftx3)\n",
    "\n",
    "    magComplex = tf.cast(sound2, tf.complex64)\n",
    "    phaseComplex = tf.cast(phase, tf.complex64)\n",
    "    spectrogramx = magComplex * tf.math.exp(1j * phaseComplex)\n",
    "    spectrogramx = tf.squeeze(spectrogramx)\n",
    "    inverse_stftx4 = tf.signal.inverse_stft(spectrogramx, 512, 128)\n",
    "    inverse_stftx4 = tf.squeeze(inverse_stftx4)\n",
    "\n",
    "    magComplex = tf.cast(predictedOutput2, tf.complex64)\n",
    "    phaseComplex = tf.cast(phase, tf.complex64)\n",
    "    spectrogramx = magComplex * tf.math.exp(1j * phaseComplex)\n",
    "    spectrogramx = tf.squeeze(spectrogramx)\n",
    "    inverse_stftx5 = tf.signal.inverse_stft(spectrogramx, 512, 128)\n",
    "    inverse_stftx5 = tf.squeeze(inverse_stftx5)\n",
    "\n",
    "    magComplex = tf.cast(sound3, tf.complex64)\n",
    "    phaseComplex = tf.cast(phase, tf.complex64)\n",
    "    spectrogramx = magComplex * tf.math.exp(1j * phaseComplex)\n",
    "    spectrogramx = tf.squeeze(spectrogramx)\n",
    "    inverse_stftx6 = tf.signal.inverse_stft(spectrogramx, 512, 128)\n",
    "    inverse_stftx6 = tf.squeeze(inverse_stftx6)\n",
    "\n",
    "    magComplex = tf.cast(predictedOutput3, tf.complex64)\n",
    "    phaseComplex = tf.cast(phase, tf.complex64)\n",
    "    spectrogramx = magComplex * tf.math.exp(1j * phaseComplex)\n",
    "    spectrogramx = tf.squeeze(spectrogramx)\n",
    "    inverse_stftx7 = tf.signal.inverse_stft(spectrogramx, 512, 128)\n",
    "    inverse_stftx7 = tf.squeeze(inverse_stftx7)\n",
    "\n",
    "    # Prepare to process data\n",
    "    string = str(label.numpy())\n",
    "    length = len(string) \n",
    "    # Calculate metrics for Mixtures\n",
    "    if (string[2:length-1] == \"Mixture\"):\n",
    "        # Save inverse stfts into \"References\" and \"Estimates\" folders\n",
    "        file0 = tf.audio.encode_wav(tf.expand_dims(inverse_stftx0, 1), 16000, name=None)\n",
    "        tf.io.write_file(\"References/file0.wav\", file0, name=None)\n",
    "        file1 = tf.audio.encode_wav(tf.expand_dims(inverse_stftx1, 1), 16000, name=None)\n",
    "        tf.io.write_file(\"Estimates/file0.wav\", file1, name=None)\n",
    "\n",
    "        file2 = tf.audio.encode_wav(tf.expand_dims(inverse_stftx2, 1), 16000, name=None)\n",
    "        tf.io.write_file(\"References/file1.wav\", file2, name=None)\n",
    "        file3 = tf.audio.encode_wav(tf.expand_dims(inverse_stftx3, 1), 16000, name=None)\n",
    "        tf.io.write_file(\"Estimates/file1.wav\", file3, name=None)\n",
    "\n",
    "        file4 = tf.audio.encode_wav(tf.expand_dims(inverse_stftx4, 1), 16000, name=None)\n",
    "        tf.io.write_file(\"References/file2.wav\", file4, name=None)\n",
    "        file5 = tf.audio.encode_wav(tf.expand_dims(inverse_stftx5, 1), 16000, name=None)\n",
    "        tf.io.write_file(\"Estimates/file2.wav\", file5, name=None)\n",
    "\n",
    "        file6 = tf.audio.encode_wav(tf.expand_dims(inverse_stftx6, 1), 16000, name=None)\n",
    "        tf.io.write_file(\"References/file3.wav\", file6, name=None)\n",
    "        file7 = tf.audio.encode_wav(tf.expand_dims(inverse_stftx7, 1), 16000, name=None)\n",
    "        tf.io.write_file(\"Estimates/file3.wav\", file7, name=None)\n",
    "\n",
    "        # Read in saved inverse stfts\n",
    "        fs, ref0 = wavfile.read(\"References/file0.wav\")\n",
    "        fs, est0 = wavfile.read(\"Estimates/file0.wav\")\n",
    "        fs, ref1 = wavfile.read(\"References/file1.wav\")\n",
    "        fs, est1 = wavfile.read(\"Estimates/file1.wav\")\n",
    "        fs, ref2 = wavfile.read(\"References/file2.wav\")\n",
    "        fs, est2 = wavfile.read(\"Estimates/file2.wav\")\n",
    "        fs, ref3 = wavfile.read(\"References/file3.wav\")\n",
    "        fs, est3 = wavfile.read(\"Estimates/file3.wav\")\n",
    "        \n",
    "        # Vacuum Alarm\n",
    "        # Error checking (code utilized from Museval)\n",
    "        if (not ((np.any(np.all(np.sum(ref0, axis=tuple(range(2, ref0.ndim))) == 0, axis=0))\n",
    "           or np.any(np.all(np.sum(est0, axis=tuple(range(2, est0.ndim))) == 0, axis=0)))\n",
    "           or (np.any(np.all(np.sum(ref1, axis=tuple(range(2, ref1.ndim))) == 0, axis=0))\n",
    "           or np.any(np.all(np.sum(est1, axis=tuple(range(2, est1.ndim))) == 0, axis=0))))):\n",
    "            \n",
    "            os.remove(\"References/file2.wav\")\n",
    "            os.remove(\"Estimates/file2.wav\")\n",
    "            os.remove(\"References/file3.wav\")\n",
    "            os.remove(\"Estimates/file3.wav\")\n",
    "            \n",
    "            # Calculate scores, save in \"test.json\"\n",
    "            scores = museval.eval_dir(\"References\", \"Estimates\", \"Outputs\")\n",
    "            scores.save(\"test.json\")\n",
    "\n",
    "            # compute the metrics\n",
    "            f = open('test.json',)\n",
    "\n",
    "            # returns JSON object as\n",
    "            # a dictionary\n",
    "            data = json.load(f)\n",
    "\n",
    "            # Iterating through the json\n",
    "            # list\n",
    "            # Metrics: Vacuum\n",
    "            jsonData = data['targets'][1]['frames'][0]['metrics']\n",
    "            sdrTemp = jsonData.get('SDR')\n",
    "            sirTemp = jsonData.get('SIR')\n",
    "            sarTemp = jsonData.get('SAR')\n",
    "            if (not (math.isnan(sdrTemp))):\n",
    "                sdrV = sdrV + sdrTemp\n",
    "                vcCSDR = vcCSDR + 1\n",
    "            if (not (math.isnan(sirTemp))):\n",
    "                sirV = sirV + sirTemp\n",
    "                vcCSIR = vcCSIR + 1\n",
    "            if (not (math.isnan(sarTemp))):\n",
    "                sarV = sarV + sarTemp\n",
    "                vcCSAR = vcCSAR + 1\n",
    "\n",
    "            # Metrics: Alarm\n",
    "            jsonData = data['targets'][0]['frames'][0]['metrics']\n",
    "            sdrTemp = jsonData.get('SDR')\n",
    "            sirTemp = jsonData.get('SIR')\n",
    "            sarTemp = jsonData.get('SAR')\n",
    "            if (not (math.isnan(sdrTemp))):\n",
    "                sdrA = sdrA + sdrTemp\n",
    "                aCSDR = aCSDR + 1\n",
    "            if (not (math.isnan(sirTemp))):\n",
    "                sirA = sirA + sirTemp\n",
    "                aCSIR = aCSIR + 1\n",
    "            if (not (math.isnan(sarTemp))):\n",
    "                sarA = sarA + sarTemp\n",
    "                aCSAR = aCSAR + 1\n",
    "        \n",
    "        # Vacuum Water\n",
    "        # Error checking\n",
    "        if (not ((np.any(np.all(np.sum(ref0, axis=tuple(range(2, ref0.ndim))) == 0, axis=0))\n",
    "           or np.any(np.all(np.sum(est0, axis=tuple(range(2, est0.ndim))) == 0, axis=0)))\n",
    "           or (np.any(np.all(np.sum(ref2, axis=tuple(range(2, ref2.ndim))) == 0, axis=0))\n",
    "           or np.any(np.all(np.sum(est2, axis=tuple(range(2, est2.ndim))) == 0, axis=0))))):\n",
    "            \n",
    "            os.remove(\"References/file1.wav\")\n",
    "            os.remove(\"Estimates/file1.wav\")\n",
    "            os.remove(\"References/file3.wav\")\n",
    "            os.remove(\"Estimates/file3.wav\")\n",
    "            \n",
    "            # Calculate scores, save in \"test.json\"\n",
    "            scores = museval.eval_dir(\"References\", \"Estimates\", \"Outputs\")\n",
    "            scores.save(\"test.json\")\n",
    "\n",
    "            # compute the metrics\n",
    "            f = open('test.json',)\n",
    "\n",
    "            # returns JSON object as\n",
    "            # a dictionary\n",
    "            data = json.load(f)\n",
    "\n",
    "            # Iterating through the json\n",
    "            # list\n",
    "            # Metrics: Vacuum\n",
    "            jsonData = data['targets'][1]['frames'][0]['metrics']\n",
    "            sdrTemp = jsonData.get('SDR')\n",
    "            sirTemp = jsonData.get('SIR')\n",
    "            sarTemp = jsonData.get('SAR')\n",
    "            if (not (math.isnan(sdrTemp))):\n",
    "                sdrV = sdrV + sdrTemp\n",
    "                vcCSDR = vcCSDR + 1\n",
    "            if (not (math.isnan(sirTemp))):\n",
    "                sirV = sirV + sirTemp\n",
    "                vcCSIR = vcCSIR + 1\n",
    "            if (not (math.isnan(sarTemp))):\n",
    "                sarV = sarV + sarTemp\n",
    "                vcCSAR = vcCSAR + 1\n",
    "\n",
    "            # Metrics: Water\n",
    "            jsonData = data['targets'][0]['frames'][0]['metrics']\n",
    "            sdrTemp = jsonData.get('SDR')\n",
    "            sirTemp = jsonData.get('SIR')\n",
    "            sarTemp = jsonData.get('SAR')\n",
    "            if (not (math.isnan(sdrTemp))):\n",
    "                sdrW = sdrW + sdrTemp\n",
    "                wCSDR = wCSDR + 1\n",
    "            if (not (math.isnan(sirTemp))):\n",
    "                sirW = sirW + sirTemp\n",
    "                wCSIR = wCSIR + 1\n",
    "            if (not (math.isnan(sarTemp))):\n",
    "                sarW = sarW + sarTemp\n",
    "                wCSAR = wCSAR + 1\n",
    "        \n",
    "        # Vacuum Dog\n",
    "        # Error checking\n",
    "        if (not ((np.any(np.all(np.sum(ref0, axis=tuple(range(2, ref0.ndim))) == 0, axis=0))\n",
    "           or np.any(np.all(np.sum(est0, axis=tuple(range(2, est0.ndim))) == 0, axis=0)))\n",
    "           or (np.any(np.all(np.sum(ref3, axis=tuple(range(2, ref3.ndim))) == 0, axis=0))\n",
    "           or np.any(np.all(np.sum(est3, axis=tuple(range(2, est3.ndim))) == 0, axis=0))))):\n",
    "            \n",
    "            os.remove(\"References/file1.wav\")\n",
    "            os.remove(\"Estimates/file1.wav\")\n",
    "            os.remove(\"References/file2.wav\")\n",
    "            os.remove(\"Estimates/file2.wav\")\n",
    "            \n",
    "            # Calculate scores, save in \"test.json\"\n",
    "            scores = museval.eval_dir(\"References\", \"Estimates\", \"Outputs\")\n",
    "            scores.save(\"test.json\")\n",
    "\n",
    "            # compute the metrics\n",
    "            f = open('test.json',)\n",
    "\n",
    "            # returns JSON object as\n",
    "            # a dictionary\n",
    "            data = json.load(f)\n",
    "\n",
    "            # Iterating through the json\n",
    "            # list\n",
    "            # Metrics: Vacuum\n",
    "            jsonData = data['targets'][1]['frames'][0]['metrics']\n",
    "            sdrTemp = jsonData.get('SDR')\n",
    "            sirTemp = jsonData.get('SIR')\n",
    "            sarTemp = jsonData.get('SAR')\n",
    "            if (not (math.isnan(sdrTemp))):\n",
    "                sdrV = sdrV + sdrTemp\n",
    "                vcCSDR = vcCSDR + 1\n",
    "            if (not (math.isnan(sirTemp))):\n",
    "                sirV = sirV + sirTemp\n",
    "                vcCSIR = vcCSIR + 1\n",
    "            if (not (math.isnan(sarTemp))):\n",
    "                sarV = sarV + sarTemp\n",
    "                vcCSAR = vcCSAR + 1\n",
    "\n",
    "            # Metrics: Dog\n",
    "            jsonData = data['targets'][0]['frames'][0]['metrics']\n",
    "            sdrTemp = jsonData.get('SDR')\n",
    "            sirTemp = jsonData.get('SIR')\n",
    "            sarTemp = jsonData.get('SAR')\n",
    "            if (not (math.isnan(sdrTemp))):\n",
    "                sdrD = sdrD + sdrTemp\n",
    "                dCSDR = dCSDR + 1\n",
    "            if (not (math.isnan(sirTemp))):\n",
    "                sirD = sirD + sirTemp\n",
    "                dCSIR = dCSIR + 1\n",
    "            if (not (math.isnan(sarTemp))):\n",
    "                sarD = sarD + sarTemp\n",
    "                dCSAR = dCSAR + 1\n",
    "        \n",
    "        # Alarm Water\n",
    "        # Error checking\n",
    "        if (not ((np.any(np.all(np.sum(ref1, axis=tuple(range(2, ref1.ndim))) == 0, axis=0))\n",
    "           or np.any(np.all(np.sum(est1, axis=tuple(range(2, est1.ndim))) == 0, axis=0)))\n",
    "           or (np.any(np.all(np.sum(ref2, axis=tuple(range(2, ref2.ndim))) == 0, axis=0))\n",
    "           or np.any(np.all(np.sum(est2, axis=tuple(range(2, est2.ndim))) == 0, axis=0))))):\n",
    "            \n",
    "            os.remove(\"References/file0.wav\")\n",
    "            os.remove(\"Estimates/file0.wav\")\n",
    "            os.remove(\"References/file3.wav\")\n",
    "            os.remove(\"Estimates/file3.wav\")\n",
    "            \n",
    "            # Calculate scores, save in \"test.json\"\n",
    "            scores = museval.eval_dir(\"References\", \"Estimates\", \"Outputs\")\n",
    "            scores.save(\"test.json\")\n",
    "\n",
    "            # compute the metrics\n",
    "            f = open('test.json',)\n",
    "\n",
    "            # returns JSON object as\n",
    "            # a dictionary\n",
    "            data = json.load(f)\n",
    "\n",
    "            # Iterating through the json\n",
    "            # list\n",
    "            # Metrics: Alarm\n",
    "            jsonData = data['targets'][1]['frames'][0]['metrics']\n",
    "            sdrTemp = jsonData.get('SDR')\n",
    "            sirTemp = jsonData.get('SIR')\n",
    "            sarTemp = jsonData.get('SAR')\n",
    "            if (not (math.isnan(sdrTemp))):\n",
    "                sdrA = sdrA + sdrTemp\n",
    "                aCSDR = aCSDR + 1\n",
    "            if (not (math.isnan(sirTemp))):\n",
    "                sirA = sirA + sirTemp\n",
    "                aCSIR = aCSIR + 1\n",
    "            if (not (math.isnan(sarTemp))):\n",
    "                sarA = sarA + sarTemp\n",
    "                aCSAR = aCSAR + 1\n",
    "\n",
    "            # Metrics: Water\n",
    "            jsonData = data['targets'][0]['frames'][0]['metrics']\n",
    "            sdrTemp = jsonData.get('SDR')\n",
    "            sirTemp = jsonData.get('SIR')\n",
    "            sarTemp = jsonData.get('SAR')\n",
    "            if (not (math.isnan(sdrTemp))):\n",
    "                sdrW = sdrW + sdrTemp\n",
    "                wCSDR = wCSDR + 1\n",
    "            if (not (math.isnan(sirTemp))):\n",
    "                sirW = sirW + sirTemp\n",
    "                wCSIR = wCSIR + 1\n",
    "            if (not (math.isnan(sarTemp))):\n",
    "                sarW = sarW + sarTemp\n",
    "                wCSAR = wCSAR + 1\n",
    "        \n",
    "        # Alarm Dog\n",
    "        # Error checking\n",
    "        if (not ((np.any(np.all(np.sum(ref1, axis=tuple(range(2, ref1.ndim))) == 0, axis=0))\n",
    "           or np.any(np.all(np.sum(est1, axis=tuple(range(2, est1.ndim))) == 0, axis=0)))\n",
    "           or (np.any(np.all(np.sum(ref3, axis=tuple(range(2, ref3.ndim))) == 0, axis=0))\n",
    "           or np.any(np.all(np.sum(est3, axis=tuple(range(2, est3.ndim))) == 0, axis=0))))):\n",
    "            \n",
    "            os.remove(\"References/file0.wav\")\n",
    "            os.remove(\"Estimates/file0.wav\")\n",
    "            os.remove(\"References/file2.wav\")\n",
    "            os.remove(\"Estimates/file2.wav\")\n",
    "            \n",
    "            # Calculate scores, save in \"test.json\"\n",
    "            scores = museval.eval_dir(\"References\", \"Estimates\", \"Outputs\")\n",
    "            scores.save(\"test.json\")\n",
    "\n",
    "            # compute the metrics\n",
    "            f = open('test.json',)\n",
    "\n",
    "            # returns JSON object as\n",
    "            # a dictionary\n",
    "            data = json.load(f)\n",
    "\n",
    "            # Iterating through the json\n",
    "            # list\n",
    "            # Metrics: Alarm\n",
    "            jsonData = data['targets'][1]['frames'][0]['metrics']\n",
    "            sdrTemp = jsonData.get('SDR')\n",
    "            sirTemp = jsonData.get('SIR')\n",
    "            sarTemp = jsonData.get('SAR')\n",
    "            if (not (math.isnan(sdrTemp))):\n",
    "                sdrA = sdrA + sdrTemp\n",
    "                aCSDR = aCSDR + 1\n",
    "            if (not (math.isnan(sirTemp))):\n",
    "                sirA = sirA + sirTemp\n",
    "                aCSIR = aCSIR + 1\n",
    "            if (not (math.isnan(sarTemp))):\n",
    "                sarA = sarA + sarTemp\n",
    "                aCSAR = aCSAR + 1\n",
    "\n",
    "            # Metrics: Dog\n",
    "            jsonData = data['targets'][0]['frames'][0]['metrics']\n",
    "            sdrTemp = jsonData.get('SDR')\n",
    "            sirTemp = jsonData.get('SIR')\n",
    "            sarTemp = jsonData.get('SAR')\n",
    "            if (not (math.isnan(sdrTemp))):\n",
    "                sdrD = sdrD + sdrTemp\n",
    "                dCSDR = dCSDR + 1\n",
    "            if (not (math.isnan(sirTemp))):\n",
    "                sirD = sirD + sirTemp\n",
    "                dCSIR = dCSIR + 1\n",
    "            if (not (math.isnan(sarTemp))):\n",
    "                sarD = sarD + sarTemp\n",
    "                dCSAR = dCSAR + 1\n",
    "            \n",
    "        # Water dog\n",
    "        # Error checking\n",
    "        if (not ((np.any(np.all(np.sum(ref2, axis=tuple(range(2, ref2.ndim))) == 0, axis=0))\n",
    "           or np.any(np.all(np.sum(est2, axis=tuple(range(2, est2.ndim))) == 0, axis=0)))\n",
    "           or (np.any(np.all(np.sum(ref3, axis=tuple(range(2, ref3.ndim))) == 0, axis=0))\n",
    "           or np.any(np.all(np.sum(est3, axis=tuple(range(2, est3.ndim))) == 0, axis=0))))):\n",
    "            \n",
    "            os.remove(\"References/file0.wav\")\n",
    "            os.remove(\"Estimates/file0.wav\")\n",
    "            os.remove(\"References/file1.wav\")\n",
    "            os.remove(\"Estimates/file1.wav\")\n",
    "            \n",
    "            # Calculate scores, save in \"test.json\"\n",
    "            scores = museval.eval_dir(\"References\", \"Estimates\", \"Outputs\")\n",
    "            scores.save(\"test.json\")\n",
    "\n",
    "            # compute the metrics\n",
    "            f = open('test.json',)\n",
    "\n",
    "            # returns JSON object as\n",
    "            # a dictionary\n",
    "            data = json.load(f)\n",
    "\n",
    "            # Iterating through the json\n",
    "            # list\n",
    "            # Metrics: Water\n",
    "            jsonData = data['targets'][1]['frames'][0]['metrics']\n",
    "            sdrTemp = jsonData.get('SDR')\n",
    "            sirTemp = jsonData.get('SIR')\n",
    "            sarTemp = jsonData.get('SAR')\n",
    "            if (not (math.isnan(sdrTemp))):\n",
    "                sdrW = sdrW + sdrTemp\n",
    "                wCSDR = wCSDR + 1\n",
    "            if (not (math.isnan(sirTemp))):\n",
    "                sirW = sirW + sirTemp\n",
    "                wCSIR = wCSIR + 1\n",
    "            if (not (math.isnan(sarTemp))):\n",
    "                sarW = sarW + sarTemp\n",
    "                wCSAR = wCSAR + 1\n",
    "\n",
    "            # Metrics: Dog\n",
    "            jsonData = data['targets'][0]['frames'][0]['metrics']\n",
    "            sdrTemp = jsonData.get('SDR')\n",
    "            sirTemp = jsonData.get('SIR')\n",
    "            sarTemp = jsonData.get('SAR')\n",
    "            if (not (math.isnan(sdrTemp))):\n",
    "                sdrD = sdrD + sdrTemp\n",
    "                dCSDR = dCSDR + 1\n",
    "            if (not (math.isnan(sirTemp))):\n",
    "                sirD = sirD + sirTemp\n",
    "                dCSIR = dCSIR + 1\n",
    "            if (not (math.isnan(sarTemp))):\n",
    "                sarD = sarD + sarTemp\n",
    "                dCSAR = dCSAR + 1\n",
    "    \n",
    "    # Delete files in \"References\" and \"Estimates\" folder for next interation\n",
    "    files = glob.glob('Estimates/*.wav', recursive=True)\n",
    "    for f in files:\n",
    "        try:\n",
    "            os.remove(f)\n",
    "        except OSError as e:\n",
    "            print(\"Error: %s : %s\" % (f, e.strerror))\n",
    "    files = glob.glob('References/*.wav', recursive=True)\n",
    "    for f in files:\n",
    "        try:\n",
    "            os.remove(f)\n",
    "        except OSError as e:\n",
    "            print(\"Error: %s : %s\" % (f, e.strerror))\n",
    "\n",
    "# Print out results\n",
    "vcSDRAvg = sdrV / vcCSDR\n",
    "vcSIRAvg = sirV / vcCSIR\n",
    "vcSARAvg = sarV / vcCSAR\n",
    "aSDRAvg = sdrA / aCSDR\n",
    "aSIRAvg = sirA / aCSIR\n",
    "aSARAvg = sarA / aCSAR\n",
    "wSDRAvg = sdrW / wCSDR\n",
    "wSIRAvg = sirW / wCSIR\n",
    "wSARAvg = sarW / wCSAR\n",
    "dSDRAvg = sdrD / dCSDR\n",
    "dSIRAvg = sirD / dCSIR\n",
    "dSARAvg = sarD / dCSAR\n",
    "print(\"vcSDRAvg: \", vcSDRAvg)\n",
    "print(\"vcSIRAvg: \", vcSIRAvg)\n",
    "print(\"vcSARAvg: \", vcSARAvg)\n",
    "print(\"aSDRAvg: \", aSDRAvg)\n",
    "print(\"aSIRAvg: \", aSIRAvg)\n",
    "print(\"aSARAvg: \", aSARAvg)\n",
    "print(\"wSDRAvg: \", wSDRAvg)\n",
    "print(\"wSIRAvg: \", wSIRAvg)\n",
    "print(\"wSARAvg: \", wSARAvg)\n",
    "print(\"dSDRAvg: \", dSDRAvg)\n",
    "print(\"dSIRAvg: \", dSIRAvg)\n",
    "print(\"dSARAvg: \", dSARAvg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "VAWDDesed.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
