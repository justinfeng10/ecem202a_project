{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 3076,
     "status": "ok",
     "timestamp": 1638584454283,
     "user": {
      "displayName": "Justin Feng",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14009013728782353907"
     },
     "user_tz": 480
    },
    "id": "C6LXMJmeS5wZ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-08 22:00:30.299990: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-12-08 22:00:30.300006: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import tensorflow_io as tfio\n",
    "from IPython import display\n",
    "from scipy.io import wavfile\n",
    "import museval\n",
    "import json\n",
    "import glob\n",
    "import math\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Conv2DTranspose\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1638584454284,
     "user": {
      "displayName": "Justin Feng",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14009013728782353907"
     },
     "user_tz": 480
    },
    "id": "QMmhpBPXS3g3"
   },
   "outputs": [],
   "source": [
    "# Grab Wav file from folder\n",
    "# Preprocessing code here and below modified from \n",
    "# Tensorflow Example: Simple Audio Recognition\n",
    "# Link: https://www.tensorflow.org/tutorials/audio/simple_audio\n",
    "def decode_audio(audio_binary):\n",
    "    audio, sr = tf.audio.decode_wav(audio_binary, desired_channels=1)\n",
    "    return tf.squeeze(audio, axis=-1), sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1638584454284,
     "user": {
      "displayName": "Justin Feng",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14009013728782353907"
     },
     "user_tz": 480
    },
    "id": "Y_fJGeSFTJfb"
   },
   "outputs": [],
   "source": [
    "# For a given filepath ending with a wav file, obtain the waveform and the label\n",
    "# Function for Vacuum\n",
    "def get_waveform_and_label_vacuum(file_path):\n",
    "    label = \"Vacuum Cleaner\"\n",
    "    audio_binary = tf.io.read_file(file_path)\n",
    "    waveform, sr = decode_audio(audio_binary)\n",
    "    if (sr == 48000):\n",
    "      waveform = tfio.audio.resample(waveform, 48000, 16000, name=None)\n",
    "    else:\n",
    "      waveform = tfio.audio.resample(waveform, 44100, 16000, name=None)\n",
    "    zeros = tf.zeros([16000,])\n",
    "    return waveform, waveform, zeros, zeros, zeros, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1638584454285,
     "user": {
      "displayName": "Justin Feng",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14009013728782353907"
     },
     "user_tz": 480
    },
    "id": "Ru4_jKFFTY0q"
   },
   "outputs": [],
   "source": [
    "# For a given filepath ending with a wav file, obtain the waveform and the label\n",
    "# Function for Alarm\n",
    "def get_waveform_and_label_alarm(file_path):\n",
    "    label = \"Alarm\"\n",
    "    audio_binary = tf.io.read_file(file_path)\n",
    "    waveform, sr = decode_audio(audio_binary)\n",
    "    if (sr == 48000):\n",
    "      waveform = tfio.audio.resample(waveform, 48000, 16000, name=None)\n",
    "    else:\n",
    "      waveform = tfio.audio.resample(waveform, 44100, 16000, name=None)\n",
    "    zeros = tf.zeros([16000,])\n",
    "    return waveform, zeros, waveform, zeros, zeros, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1638584454285,
     "user": {
      "displayName": "Justin Feng",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14009013728782353907"
     },
     "user_tz": 480
    },
    "id": "cH_NkIB2b2PU"
   },
   "outputs": [],
   "source": [
    "# For a given filepath ending with a wav file, obtain the waveform and the label\n",
    "# Function for Water\n",
    "def get_waveform_and_label_water(file_path):\n",
    "    label = \"Water\"\n",
    "    audio_binary = tf.io.read_file(file_path)\n",
    "    waveform, sr = decode_audio(audio_binary)\n",
    "    waveform = tfio.audio.resample(waveform, 44100, 16000, name=None)\n",
    "    zeros = tf.zeros([16000,])\n",
    "    return waveform, zeros, zeros, waveform, zeros, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1638584454286,
     "user": {
      "displayName": "Justin Feng",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14009013728782353907"
     },
     "user_tz": 480
    },
    "id": "4ZgiQuhAb2W-"
   },
   "outputs": [],
   "source": [
    "# For a given filepath ending with a wav file, obtain the waveform and the label\n",
    "# Function for Dog\n",
    "def get_waveform_and_label_dog(file_path):\n",
    "    label = \"Dog\"\n",
    "    audio_binary = tf.io.read_file(file_path)\n",
    "    waveform, sr = decode_audio(audio_binary)\n",
    "    if (sr == 48000):\n",
    "      waveform = tfio.audio.resample(waveform, 48000, 16000, name=None)\n",
    "    else:\n",
    "      waveform = tfio.audio.resample(waveform, 44100, 16000, name=None)\n",
    "    zeros = tf.zeros([16000,])\n",
    "    return waveform, zeros, zeros, zeros, waveform, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1638584454286,
     "user": {
      "displayName": "Justin Feng",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14009013728782353907"
     },
     "user_tz": 480
    },
    "id": "KLzgwIviVadz"
   },
   "outputs": [],
   "source": [
    "# For a given filepath ending with a wav file, obtain the waveform and the label\n",
    "# Function for MIXTURE\n",
    "def get_waveform_and_label_mixture(file_path):\n",
    "    label = \"Mixture\"\n",
    "    audio_binary = tf.io.read_file(file_path)\n",
    "    waveform, sr = decode_audio(audio_binary)\n",
    "    if (sr == 48000):\n",
    "      waveform = tfio.audio.resample(waveform, 48000, 16000, name=None)\n",
    "    else:\n",
    "      waveform = tfio.audio.resample(waveform, 44100, 16000, name=None)\n",
    "    \n",
    "    # Obtain original files for vacuum and pouring\n",
    "    audio_binary = tf.io.read_file(file_path + \"Label/0.wav\")\n",
    "    vacuumCleanerLabel, sr = decode_audio(audio_binary)\n",
    "    if (sr == 48000):\n",
    "      vacuumCleanerLabel = tfio.audio.resample(vacuumCleanerLabel, 48000, 16000, name=None)\n",
    "    else:\n",
    "      vacuumCleanerLabel = tfio.audio.resample(vacuumCleanerLabel, 44100, 16000, name=None)\n",
    "    audio_binary = tf.io.read_file(file_path + \"Label/1.wav\")\n",
    "    alarmLabel, sr = decode_audio(audio_binary)\n",
    "    if (sr == 48000):\n",
    "      alarmLabel = tfio.audio.resample(alarmLabel, 48000, 16000, name=None)\n",
    "    else:\n",
    "      alarmLabel = tfio.audio.resample(alarmLabel, 44100, 16000, name=None)\n",
    "    audio_binary = tf.io.read_file(file_path + \"Label/2.wav\")\n",
    "    waterLabel, sr = decode_audio(audio_binary)\n",
    "    if (sr == 48000):\n",
    "      waterLabel = tfio.audio.resample(waterLabel, 48000, 16000, name=None)\n",
    "    else:\n",
    "      waterLabel = tfio.audio.resample(waterLabel, 44100, 16000, name=None)\n",
    "    audio_binary = tf.io.read_file(file_path + \"Label/3.wav\")\n",
    "    dogLabel, sr = decode_audio(audio_binary)\n",
    "    if (sr == 48000):\n",
    "      dogLabel = tfio.audio.resample(dogLabel, 48000, 16000, name=None)\n",
    "    else:\n",
    "      dogLabel = tfio.audio.resample(dogLabel, 44100, 16000, name=None)\n",
    "\n",
    "    return waveform, vacuumCleanerLabel, alarmLabel, waterLabel, dogLabel, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3368,
     "status": "ok",
     "timestamp": 1638584457645,
     "user": {
      "displayName": "Justin Feng",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14009013728782353907"
     },
     "user_tz": 480
    },
    "id": "R9mxMMQaTgoc",
    "outputId": "f141e768-46e8-49c0-a17b-eba437c1522e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-08 22:00:31.586843: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-12-08 22:00:31.586867: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-12-08 22:00:31.586885: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (jfeng-ThinkPad-X1-Yoga-Gen-6): /proc/driver/nvidia/version does not exist\n",
      "2021-12-08 22:00:31.587140: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-08 22:00:31.685888: I tensorflow_io/core/kernels/cpu_check.cc:128] Your CPU supports instructions that this TensorFlow IO binary was not compiled to use: AVX2 AVX512F FMA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n",
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    }
   ],
   "source": [
    "# Dataset: Vacuum\n",
    "data_dir = pathlib.Path('Sounds/Esc/VacuumCleanerCut')\n",
    "filenames = tf.io.gfile.glob(str(data_dir) + '/*')\n",
    "filenames = tf.random.shuffle(filenames)\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "files_ds = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "waveformVacuum_ds = files_ds.map(get_waveform_and_label_vacuum, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 422,
     "status": "ok",
     "timestamp": 1638584458282,
     "user": {
      "displayName": "Justin Feng",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14009013728782353907"
     },
     "user_tz": 480
    },
    "id": "RhtKlTI8TmR4",
    "outputId": "a7d21803-0253-4847-d456-97383e4dc124"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n",
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    }
   ],
   "source": [
    "# Dataset: Alarm\n",
    "data_dir = pathlib.Path('Sounds/Esc/AlarmCut')\n",
    "filenames = tf.io.gfile.glob(str(data_dir) + '/*')\n",
    "filenames = tf.random.shuffle(filenames)\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "files_ds = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "waveformAlarm_ds = files_ds.map(get_waveform_and_label_alarm, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 193,
     "status": "ok",
     "timestamp": 1638584458466,
     "user": {
      "displayName": "Justin Feng",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14009013728782353907"
     },
     "user_tz": 480
    },
    "id": "maqF3GMbd5Jv",
    "outputId": "870a07e4-cf3a-4b0f-d724-0fe52bfb2ff8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    }
   ],
   "source": [
    "# Dataset: Water\n",
    "data_dir = pathlib.Path('Sounds/Esc/PouringWaterCut')\n",
    "filenames = tf.io.gfile.glob(str(data_dir) + '/*')\n",
    "filenames = tf.random.shuffle(filenames)\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "files_ds = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "waveformWater_ds = files_ds.map(get_waveform_and_label_water, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 433,
     "status": "ok",
     "timestamp": 1638584458896,
     "user": {
      "displayName": "Justin Feng",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14009013728782353907"
     },
     "user_tz": 480
    },
    "id": "4OJpfLEjeAaH",
    "outputId": "994c8491-0ef8-48f4-ae78-d06f8850a07e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n",
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    }
   ],
   "source": [
    "# Dataset: Dog\n",
    "data_dir = pathlib.Path('Sounds/Esc/DogCut')\n",
    "filenames = tf.io.gfile.glob(str(data_dir) + '/*')\n",
    "filenames = tf.random.shuffle(filenames)\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "files_ds = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "waveformDog_ds = files_ds.map(get_waveform_and_label_dog, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10259,
     "status": "ok",
     "timestamp": 1638584469150,
     "user": {
      "displayName": "Justin Feng",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14009013728782353907"
     },
     "user_tz": 480
    },
    "id": "SpD1L8r0T6LX",
    "outputId": "89239db9-a07e-4bfa-c492-a63852f92355"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n",
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n",
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n",
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n",
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n",
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n",
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n",
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n",
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n",
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    }
   ],
   "source": [
    "# Dataset: Mixtures\n",
    "data_dir = pathlib.Path('Sounds/Esc/MixturesVAWD')\n",
    "filenames = tf.io.gfile.glob(str(data_dir) + '/*1.wav')\n",
    "filenames = tf.random.shuffle(filenames)\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "files_ds = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "waveformMixture_ds = files_ds.map(get_waveform_and_label_mixture, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1638584469150,
     "user": {
      "displayName": "Justin Feng",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14009013728782353907"
     },
     "user_tz": 480
    },
    "id": "lEXFNGTVtY5s"
   },
   "outputs": [],
   "source": [
    "# Add the mixture structure to the existing structure of singular wav files\n",
    "waveform_esc_ds = waveformVacuum_ds.concatenate(waveformAlarm_ds)\n",
    "waveform_esc_ds = waveform_esc_ds.concatenate(waveformWater_ds)\n",
    "waveform_esc_ds = waveform_esc_ds.concatenate(waveformDog_ds)\n",
    "waveform_esc_ds = waveform_esc_ds.concatenate(waveformMixture_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2461,
     "status": "ok",
     "timestamp": 1638584471591,
     "user": {
      "displayName": "Justin Feng",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14009013728782353907"
     },
     "user_tz": 480
    },
    "id": "ejhBiAWpqod4",
    "outputId": "caa62b5b-4c47-4fa3-a694-f524a84ac481"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n",
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    }
   ],
   "source": [
    "# Dataset: Vacuum\n",
    "data_dir = pathlib.Path('Sounds/Desed/Vacuum_cleanerCut')\n",
    "filenames = tf.io.gfile.glob(str(data_dir) + '/*')\n",
    "filenames = tf.random.shuffle(filenames)\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "files_ds = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "waveformVacuum_ds = files_ds.map(get_waveform_and_label_vacuum, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1486,
     "status": "ok",
     "timestamp": 1638584473072,
     "user": {
      "displayName": "Justin Feng",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14009013728782353907"
     },
     "user_tz": 480
    },
    "id": "JNDVYluEqo-u",
    "outputId": "df604ac6-f73a-4f5e-a034-b57aea151c65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n",
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    }
   ],
   "source": [
    "# Dataset: Alarm\n",
    "data_dir = pathlib.Path('Sounds/Desed/Alarm_bell_ringingCut')\n",
    "filenames = tf.io.gfile.glob(str(data_dir) + '/*')\n",
    "filenames = tf.random.shuffle(filenames)\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "files_ds = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "waveformAlarm_ds = files_ds.map(get_waveform_and_label_alarm, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 228,
     "status": "ok",
     "timestamp": 1638584473292,
     "user": {
      "displayName": "Justin Feng",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14009013728782353907"
     },
     "user_tz": 480
    },
    "id": "J7ZsJTPt98yC",
    "outputId": "841ea677-435b-4a21-ed4c-dd55797feefa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    }
   ],
   "source": [
    "# Dataset: Water\n",
    "data_dir = pathlib.Path('Sounds/Desed/Running_waterCut')\n",
    "filenames = tf.io.gfile.glob(str(data_dir) + '/*')\n",
    "filenames = tf.random.shuffle(filenames)\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "files_ds = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "waveformWater_ds = files_ds.map(get_waveform_and_label_water, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 450,
     "status": "ok",
     "timestamp": 1638584473735,
     "user": {
      "displayName": "Justin Feng",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14009013728782353907"
     },
     "user_tz": 480
    },
    "id": "PQhfnzQD-E-T",
    "outputId": "a638517c-1c19-465e-fe78-810b8dea1821"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n",
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    }
   ],
   "source": [
    "# Dataset: Dog\n",
    "data_dir = pathlib.Path('Sounds/Desed/DogCut')\n",
    "filenames = tf.io.gfile.glob(str(data_dir) + '/*')\n",
    "filenames = tf.random.shuffle(filenames)\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "files_ds = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "waveformDog_ds = files_ds.map(get_waveform_and_label_dog, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9508,
     "status": "ok",
     "timestamp": 1638584483240,
     "user": {
      "displayName": "Justin Feng",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14009013728782353907"
     },
     "user_tz": 480
    },
    "id": "v2itRUXNqrOT",
    "outputId": "5d11805a-1557-4c7c-d8ec-d3bdc23e54d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n",
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n",
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n",
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n",
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n",
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n",
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n",
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n",
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n",
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    }
   ],
   "source": [
    "# Dataset: Mixture\n",
    "data_dir = pathlib.Path('Sounds/Desed/MixturesVAWD')\n",
    "filenames = tf.io.gfile.glob(str(data_dir) + '/*1.wav')\n",
    "filenames = tf.random.shuffle(filenames)\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "files_ds = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "waveformMixture_ds = files_ds.map(get_waveform_and_label_mixture, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1638584483240,
     "user": {
      "displayName": "Justin Feng",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14009013728782353907"
     },
     "user_tz": 480
    },
    "id": "bCql4BHOq2Kn"
   },
   "outputs": [],
   "source": [
    "# Add the mixture structure to the existing structure of singular wav files, then mix up wav files\n",
    "# Choose a selection of singular files\n",
    "waveformVacuum_ds = waveformVacuum_ds.shuffle(345, reshuffle_each_iteration=False).take(100)\n",
    "waveformAlarm_ds = waveformAlarm_ds.shuffle(290, reshuffle_each_iteration=False).take(100)\n",
    "waveformWater_ds = waveformWater_ds.shuffle(315, reshuffle_each_iteration=False).take(100)\n",
    "waveformDog_ds = waveformDog_ds.shuffle(265, reshuffle_each_iteration=False).take(100)\n",
    "waveformMixture_ds = waveformMixture_ds.shuffle(1200, reshuffle_each_iteration=False).take(400)\n",
    "waveform_desed_ds = waveformVacuum_ds.concatenate(waveformAlarm_ds)\n",
    "waveform_desed_ds = waveform_desed_ds.concatenate(waveformWater_ds)\n",
    "waveform_desed_ds = waveform_desed_ds.concatenate(waveformDog_ds)\n",
    "waveform_desed_ds = waveform_desed_ds.concatenate(waveformMixture_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1638584483240,
     "user": {
      "displayName": "Justin Feng",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14009013728782353907"
     },
     "user_tz": 480
    },
    "id": "kL6Ub1mhrA3C"
   },
   "outputs": [],
   "source": [
    "# Concatenate ESC and Desed datasets, then shuffle\n",
    "waveform_ds = waveform_esc_ds.concatenate(waveform_desed_ds)\n",
    "waveform_ds = waveform_ds.shuffle(2400, reshuffle_each_iteration=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1638584483241,
     "user": {
      "displayName": "Justin Feng",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14009013728782353907"
     },
     "user_tz": 480
    },
    "id": "9-i_rHHgtqNV"
   },
   "outputs": [],
   "source": [
    "# Calculate spectrogram\n",
    "def get_spectrogram(waveform):\n",
    "    spectrogram = tf.signal.stft(waveform, frame_length=512, frame_step=128)\n",
    "    return spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1638584483241,
     "user": {
      "displayName": "Justin Feng",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14009013728782353907"
     },
     "user_tz": 480
    },
    "id": "HNKrES46tts9"
   },
   "outputs": [],
   "source": [
    "# Plot spectrogram, given a spectrogram and an axis\n",
    "def plot_spectrogram(spectrogram, ax):\n",
    "    # Convert to frequencies to log scale and transpose so that the time is\n",
    "    # represented in the x-axis (columns). An epsilon is added to avoid log of zero.\n",
    "    log_spec = np.log(spectrogram.T+np.finfo(float).eps)\n",
    "    height = log_spec.shape[0]\n",
    "    width = log_spec.shape[1]\n",
    "    X = np.linspace(0, np.size(spectrogram), num=width, dtype=int)\n",
    "    Y = range(height)\n",
    "    ax.pcolormesh(X, Y, log_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1638584483241,
     "user": {
      "displayName": "Justin Feng",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14009013728782353907"
     },
     "user_tz": 480
    },
    "id": "NxX81BJstyHU"
   },
   "outputs": [],
   "source": [
    "# Given the raw input (audio), and the components that make up\n",
    "# the input (label0, label1, label2, label3), and the actual label, compute\n",
    "# the spectrograms and return the phase of the raw input\n",
    "def get_spectrogram_and_label_id(audio, label0, label1, label2, label3, label):\n",
    "    spectrogram = get_spectrogram(audio)\n",
    "    spectrogram0 = get_spectrogram(label0)\n",
    "    spectrogram1 = get_spectrogram(label1)\n",
    "    spectrogram2 = get_spectrogram(label2)\n",
    "    spectrogram3 = get_spectrogram(label3)\n",
    "    label_id = label\n",
    "    return spectrogram, spectrogram0, spectrogram1, spectrogram2, spectrogram3, label_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 928159,
     "status": "ok",
     "timestamp": 1638585411396,
     "user": {
      "displayName": "Justin Feng",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14009013728782353907"
     },
     "user_tz": 480
    },
    "id": "ibnE15Ljt0nf"
   },
   "outputs": [],
   "source": [
    "# Dataset: spectrograms\n",
    "spectrogram_ds = waveform_ds.map(\n",
    "    get_spectrogram_and_label_id, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "# Define train, validation, test datasets\n",
    "train_size = int(0.8*2400)\n",
    "val_size = int(0.1*2400)\n",
    "train_ds = spectrogram_ds.take(train_size)    \n",
    "val_ds = spectrogram_ds.skip(train_size).take(val_size)\n",
    "test_ds = spectrogram_ds.skip(train_size).skip(val_size)\n",
    "\n",
    "# Save test dataset\n",
    "path = \"test_dataset_VAWDComplex\"\n",
    "tf.data.experimental.save(test_ds, path)\n",
    "new_dataset = tf.data.experimental.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1638585411852,
     "user": {
      "displayName": "Justin Feng",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14009013728782353907"
     },
     "user_tz": 480
    },
    "id": "A3Mc6HWIt75A"
   },
   "outputs": [],
   "source": [
    "# Batch the training input\n",
    "batch_size = 2\n",
    "train_ds = train_ds.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1638585411853,
     "user": {
      "displayName": "Justin Feng",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14009013728782353907"
     },
     "user_tz": 480
    },
    "id": "sR9Jz8Pdt9Ca"
   },
   "outputs": [],
   "source": [
    "# Source Separation ML Model\n",
    "class SourceSeparationModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(SourceSeparationModel, self).__init__()\n",
    "        # Encoder\n",
    "        self.conv1 = Conv2D(filters=30, kernel_size=(1, 257))\n",
    "        self.conv2 = Conv2D(filters=15, kernel_size=(30, 1))\n",
    "        self.d1 = Dense(units=128, activation='relu')\n",
    "        # Decoder\n",
    "        self.dClass0 = Dense(units=15, activation='relu')\n",
    "        self.dClass1 = Dense(units=15, activation='relu')\n",
    "        self.dClass2 = Dense(units=15, activation='relu')\n",
    "        self.dClass3 = Dense(units=15, activation='relu')\n",
    "        self.conv3Class0 = Conv2DTranspose(filters=15, kernel_size=(30, 1))\n",
    "        self.conv4Class0 = Conv2DTranspose(filters=30, kernel_size=(1, 257))\n",
    "        self.conv3Class1 = Conv2DTranspose(filters=15, kernel_size=(30, 1))\n",
    "        self.conv4Class1 = Conv2DTranspose(filters=30, kernel_size=(1, 257))\n",
    "        self.conv3Class2 = Conv2DTranspose(filters=15, kernel_size=(30, 1))\n",
    "        self.conv4Class2 = Conv2DTranspose(filters=30, kernel_size=(1, 257))\n",
    "        self.conv3Class3 = Conv2DTranspose(filters=15, kernel_size=(30, 1))\n",
    "        self.conv4Class3 = Conv2DTranspose(filters=30, kernel_size=(1, 257))\n",
    "        self.concat = Concatenate()\n",
    "        # Output\n",
    "        self.out = Dense(units=8, activation='relu')\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.d1(x)\n",
    "        out0 = self.dClass0(x)\n",
    "        out0 = self.conv3Class0(out0)\n",
    "        out0 = self.conv4Class0(out0)\n",
    "        out1 = self.dClass1(x)\n",
    "        out1 = self.conv3Class1(out1)\n",
    "        out1 = self.conv4Class1(out1)\n",
    "        out2 = self.dClass2(x)\n",
    "        out2 = self.conv3Class2(out2)\n",
    "        out2 = self.conv4Class2(out2)\n",
    "        out3 = self.dClass3(x)\n",
    "        out3 = self.conv3Class3(out3)\n",
    "        out3 = self.conv4Class3(out3)\n",
    "        output = self.concat([out0, out1, out2, out3])\n",
    "        return self.out(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 534,
     "status": "ok",
     "timestamp": 1638585412379,
     "user": {
      "displayName": "Justin Feng",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14009013728782353907"
     },
     "user_tz": 480
    },
    "id": "h2OG1s9Dt-7q"
   },
   "outputs": [],
   "source": [
    "# Train Function\n",
    "def train(model, optimizer, epochs):\n",
    "    train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "    # Parameter for loss function\n",
    "    alpha = 0.001\n",
    "    for epoch in range(epochs):  \n",
    "        train_loss.reset_states()\n",
    "        for x_np, spectrogram0, spectrogram1, spectrogram2, spectrogram3, label in train_ds:\n",
    "            with tf.GradientTape() as tape:\n",
    "                # Calculate magnitude and phase\n",
    "                mag = tf.abs(x_np)\n",
    "                phase = tf.math.angle(x_np)\n",
    "                complexVal = tf.stack([mag, phase], axis = 3)\n",
    "                output = model(complexVal, training=True)\n",
    "                # Isolate outputs\n",
    "                output0 = output[:, :, :, 0:2]\n",
    "                output1 = output[:, :, :, 2:4]\n",
    "                output2 = output[:, :, :, 4:6]\n",
    "                output3 = output[:, :, :, 6:8]\n",
    "                \n",
    "                # Compute time frequency mask\n",
    "                sum = tf.add(output0, output1)\n",
    "                sum = tf.add(sum, output2)\n",
    "                sum = tf.add(sum, output3)\n",
    "                filter0 = tf.math.divide_no_nan(output0, sum) \n",
    "                filter1 = tf.math.divide_no_nan(output1, sum)\n",
    "                filter2 = tf.math.divide_no_nan(output2, sum) \n",
    "                filter3 = tf.math.divide_no_nan(output3, sum)\n",
    "                \n",
    "                # Find predicted outputs\n",
    "                predictedOutput0 = tf.multiply(filter0, complexVal)\n",
    "                predictedOutput1 = tf.multiply(filter1, complexVal)\n",
    "                predictedOutput2 = tf.multiply(filter2, complexVal)\n",
    "                predictedOutput3 = tf.multiply(filter3, complexVal)\n",
    "\n",
    "                # Calculate Loss\n",
    "                mse = tf.keras.losses.MeanSquaredError(reduction=tf.keras.losses.Reduction.SUM)\n",
    "                mag0 = tf.abs(spectrogram0)\n",
    "                phase0 = tf.math.angle(spectrogram0)\n",
    "                spec0 = tf.stack([mag0, phase0], axis = 3)\n",
    "                mag1 = tf.abs(spectrogram1)\n",
    "                phase1 = tf.math.angle(spectrogram1)\n",
    "                spec1 = tf.stack([mag1, phase1], axis = 3)\n",
    "                mag2 = tf.abs(spectrogram2)\n",
    "                phase2 = tf.math.angle(spectrogram2)\n",
    "                spec2 = tf.stack([mag2, phase2], axis = 3)\n",
    "                mag3 = tf.abs(spectrogram3)\n",
    "                phase3 = tf.math.angle(spectrogram3)\n",
    "                spec3 = tf.stack([mag3, phase3], axis = 3)\n",
    "                loss0 = mse(predictedOutput0, spec0)\n",
    "                loss1 = mse(predictedOutput1, spec1)\n",
    "                loss2 = mse(predictedOutput2, spec2)\n",
    "                loss3 = mse(predictedOutput3, spec3)\n",
    "                alpha0 = alpha * mse(predictedOutput0, predictedOutput1) + alpha * mse(predictedOutput0, predictedOutput2) + alpha * mse(predictedOutput0, predictedOutput3)\n",
    "                alpha1 = alpha * mse(predictedOutput1, predictedOutput0) + alpha * mse(predictedOutput1, predictedOutput2) + alpha * mse(predictedOutput1, predictedOutput3)\n",
    "                alpha2 = alpha * mse(predictedOutput2, predictedOutput0) + alpha * mse(predictedOutput2, predictedOutput1) + alpha * mse(predictedOutput2, predictedOutput3)\n",
    "                alpha3 = alpha * mse(predictedOutput3, predictedOutput0) + alpha * mse(predictedOutput3, predictedOutput1) + alpha * mse(predictedOutput3, predictedOutput2)\n",
    "                lossTemp0 = tf.add(loss0, loss1)\n",
    "                lossTemp0 = tf.add(lossTemp0, loss2)\n",
    "                lossTemp0 = tf.add(lossTemp0, loss3)\n",
    "                lossTemp0 = tf.abs(lossTemp0)\n",
    "                lossTemp1 = tf.add(alpha0, alpha1)\n",
    "                lossTemp1 = tf.add(lossTemp1, alpha2)\n",
    "                lossTemp1 = tf.add(lossTemp1, alpha3)\n",
    "                lossTemp1 = tf.abs(lossTemp1)\n",
    "                # Subtract out differences between predicted outputs\n",
    "                loss = tf.abs(tf.subtract(lossTemp0, lossTemp1))\n",
    "                # Use original term\n",
    "                loss = lossTemp0\n",
    "\n",
    "                gradients = tape.gradient(loss, model.trainable_variables)\n",
    "                optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "                train_loss.update_state(loss)\n",
    "\n",
    "        template = 'Epoch {}, Loss: {}'\n",
    "        print(template.format(epoch+1, train_loss.result()))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7843012,
     "status": "ok",
     "timestamp": 1638593255389,
     "user": {
      "displayName": "Justin Feng",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14009013728782353907"
     },
     "user_tz": 480
    },
    "id": "BhqZzMTxuDss",
    "outputId": "ce038154-6b04-45c0-ad75-4f96c917c05d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 177029.859375\n",
      "Epoch 2, Loss: 132401.453125\n",
      "Epoch 3, Loss: 119740.109375\n",
      "Epoch 4, Loss: 109100.1171875\n",
      "Epoch 5, Loss: 106187.234375\n",
      "Epoch 6, Loss: 99321.2578125\n",
      "Epoch 7, Loss: 95320.7265625\n",
      "Epoch 8, Loss: 92454.046875\n",
      "Epoch 9, Loss: 91487.4140625\n",
      "Epoch 10, Loss: 91691.671875\n",
      "Epoch 11, Loss: 86519.828125\n",
      "Epoch 12, Loss: 84622.265625\n",
      "Epoch 13, Loss: 83138.078125\n",
      "Epoch 14, Loss: 81855.1328125\n",
      "Epoch 15, Loss: 83076.8203125\n",
      "Epoch 16, Loss: 82634.9765625\n",
      "Epoch 17, Loss: 79857.265625\n",
      "Epoch 18, Loss: 78003.1015625\n",
      "Epoch 19, Loss: 77376.1328125\n",
      "Epoch 20, Loss: 76638.078125\n",
      "Model: \"source_separation_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             multiple                  15450     \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           multiple                  13515     \n",
      "                                                                 \n",
      " dense (Dense)               multiple                  2048      \n",
      "                                                                 \n",
      " dense_1 (Dense)             multiple                  1935      \n",
      "                                                                 \n",
      " dense_2 (Dense)             multiple                  1935      \n",
      "                                                                 \n",
      " dense_3 (Dense)             multiple                  1935      \n",
      "                                                                 \n",
      " dense_4 (Dense)             multiple                  1935      \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  multiple                 6765      \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  multiple                 115680    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  multiple                 6765      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_3 (Conv2DT  multiple                 115680    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_4 (Conv2DT  multiple                 6765      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_5 (Conv2DT  multiple                 115680    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_6 (Conv2DT  multiple                 6765      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_7 (Conv2DT  multiple                 115680    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " concatenate (Concatenate)   multiple                  0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             multiple                  968       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 529,501\n",
      "Trainable params: 529,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Instantiate model\n",
    "model = SourceSeparationModel()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001, name = \"Adam\")\n",
    "train(model, optimizer, epochs=20)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3972,
     "status": "ok",
     "timestamp": 1638593357150,
     "user": {
      "displayName": "Justin Feng",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14009013728782353907"
     },
     "user_tz": 480
    },
    "id": "LTYhejP9OqYD",
    "outputId": "13a6e8ec-785f-4516-962c-cf107256cf34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/my_model_VAWDDesedComplex/assets\n"
     ]
    }
   ],
   "source": [
    "# Save the entire model as a SavedModel.\n",
    "!mkdir -p saved_model\n",
    "model.save('saved_model/my_model_VAWDComplex') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2180,
     "status": "ok",
     "timestamp": 1638593359324,
     "user": {
      "displayName": "Justin Feng",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14009013728782353907"
     },
     "user_tz": 480
    },
    "id": "Dst7QCyQOxKu",
    "outputId": "adc98842-e40c-42e4-84b7-12e73b9c662f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"source_separation_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              multiple                  15450     \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            multiple                  13515     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  2048      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  1935      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  1935      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              multiple                  1935      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              multiple                  1935      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran multiple                  6765      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr multiple                  115680    \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr multiple                  6765      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr multiple                  115680    \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr multiple                  6765      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTr multiple                  115680    \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTr multiple                  6765      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTr multiple                  115680    \n",
      "_________________________________________________________________\n",
      "concatenate (Concatenate)    multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              multiple                  968       \n",
      "=================================================================\n",
      "Total params: 529,501\n",
      "Trainable params: 529,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load saved model\n",
    "new_model = tf.keras.models.load_model('saved_model/my_model_VAWDComplex', compile=False)\n",
    "# Check its architecture\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "57jzWJZ6bjGb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vcSDRAvg:  10.502333333333334\n",
      "vcSIRAvg:  15.146469444444445\n",
      "vcSARAvg:  14.531187222222218\n",
      "aSDRAvg:  4.224463939393941\n",
      "aSIRAvg:  10.61850696969697\n",
      "aSARAvg:  4.218208333333331\n",
      "wSDRAvg:  6.452525000000001\n",
      "wSIRAvg:  10.96846104166667\n",
      "wSARAvg:  7.283863125\n",
      "dSDRAvg:  6.2579865384615365\n",
      "dSIRAvg:  13.503245384615385\n",
      "dSARAvg:  4.928667115384616\n"
     ]
    }
   ],
   "source": [
    "# Load test set\n",
    "path = \"test_dataset_VAWDComplex\"\n",
    "new_dataset = tf.data.experimental.load(path)\n",
    "# Initialize Metrics for different sources\n",
    "vcCSDR = 0\n",
    "vcCSIR = 0\n",
    "vcCSAR = 0\n",
    "aCSDR = 0\n",
    "aCSIR = 0\n",
    "aCSAR = 0\n",
    "wCSDR = 0\n",
    "wCSIR = 0\n",
    "wCSAR = 0\n",
    "dCSDR = 0\n",
    "dCSIR = 0\n",
    "dCSAR = 0\n",
    "sdrV = 0\n",
    "sdrA = 0\n",
    "sdrW = 0\n",
    "sdrD = 0\n",
    "sirV = 0\n",
    "sirA = 0\n",
    "sirW = 0\n",
    "sirD = 0\n",
    "sarV = 0\n",
    "sarA = 0\n",
    "sarW = 0\n",
    "sarD = 0\n",
    "count = 0\n",
    "for audio, sound0, sound1, sound2, sound3, label in new_dataset:\n",
    "    # Pass audio into ML model and obtain predicted outputs\n",
    "    mag = tf.abs(audio)\n",
    "    phase = tf.math.angle(audio)\n",
    "    complexVal = tf.stack([mag, phase], axis = 2)\n",
    "    complexVal = tf.expand_dims(complexVal, axis=0)\n",
    "    output = new_model(complexVal, training=True)\n",
    "    output0 = output[:, :, :, 0:2]\n",
    "    output1 = output[:, :, :, 2:4]\n",
    "    output2 = output[:, :, :, 4:6]\n",
    "    output3 = output[:, :, :, 6:8]\n",
    "    sum = tf.add(output0, output1)\n",
    "    sum = tf.add(sum, output2)\n",
    "    sum = tf.add(sum, output3)\n",
    "    filter0 = tf.math.divide_no_nan(output0, sum) \n",
    "    filter1 = tf.math.divide_no_nan(output1, sum)\n",
    "    filter2 = tf.math.divide_no_nan(output2, sum) \n",
    "    filter3 = tf.math.divide_no_nan(output3, sum)\n",
    "    predictedOutput0 = tf.multiply(filter0, complexVal)\n",
    "    predictedOutput1 = tf.multiply(filter1, complexVal)\n",
    "    predictedOutput2 = tf.multiply(filter2, complexVal)\n",
    "    predictedOutput3 = tf.multiply(filter3, complexVal)\n",
    "    sound0 = tf.expand_dims(sound0, 0)\n",
    "    sound0 = tf.expand_dims(sound0, 3)\n",
    "    sound1 = tf.expand_dims(sound1, 0)\n",
    "    sound1 = tf.expand_dims(sound1, 3)\n",
    "    sound2 = tf.expand_dims(sound2, 0)\n",
    "    sound2 = tf.expand_dims(sound2, 3)\n",
    "    sound3 = tf.expand_dims(sound3, 0)\n",
    "    sound3 = tf.expand_dims(sound3, 3)\n",
    "\n",
    "    # Calculate inverse stft for inputs as well as outputs\n",
    "    spectrogramx = tf.squeeze(sound0)\n",
    "    inverse_stftx0 = tf.signal.inverse_stft(spectrogramx, 512, 128)\n",
    "    inverse_stftx0 = tf.squeeze(inverse_stftx0)\n",
    "\n",
    "    magComplex = predictedOutput0[:, :, :, 0]\n",
    "    magComplex = tf.cast(magComplex, tf.complex64)\n",
    "    phaseComplex = predictedOutput0[:, :, :, 1]\n",
    "    phaseComplex = tf.cast(phaseComplex, tf.complex64)\n",
    "    spectrogramx = magComplex * tf.math.exp(1j * phaseComplex)\n",
    "    spectrogramx = tf.squeeze(spectrogramx)\n",
    "    inverse_stftx1 = tf.signal.inverse_stft(spectrogramx, 512, 128)\n",
    "    inverse_stftx1 = tf.squeeze(inverse_stftx1)\n",
    "\n",
    "    spectrogramx = tf.squeeze(sound1)\n",
    "    inverse_stftx2 = tf.signal.inverse_stft(spectrogramx, 512, 128)\n",
    "    inverse_stftx2 = tf.squeeze(inverse_stftx2)\n",
    "\n",
    "    magComplex = predictedOutput1[:, :, :, 0]\n",
    "    magComplex = tf.cast(magComplex, tf.complex64)\n",
    "    phaseComplex = predictedOutput1[:, :, :, 1]\n",
    "    phaseComplex = tf.cast(phaseComplex, tf.complex64)\n",
    "    spectrogramx = magComplex * tf.math.exp(1j * phaseComplex)\n",
    "    spectrogramx = tf.squeeze(spectrogramx)\n",
    "    inverse_stftx3 = tf.signal.inverse_stft(spectrogramx, 512, 128)\n",
    "    inverse_stftx3 = tf.squeeze(inverse_stftx3)\n",
    "\n",
    "    spectrogramx = tf.squeeze(sound2)\n",
    "    inverse_stftx4 = tf.signal.inverse_stft(spectrogramx, 512, 128)\n",
    "    inverse_stftx4 = tf.squeeze(inverse_stftx4)\n",
    "\n",
    "    magComplex = predictedOutput2[:, :, :, 0]\n",
    "    magComplex = tf.cast(magComplex, tf.complex64)\n",
    "    phaseComplex = predictedOutput2[:, :, :, 1]\n",
    "    phaseComplex = tf.cast(phaseComplex, tf.complex64)\n",
    "    spectrogramx = magComplex * tf.math.exp(1j * phaseComplex)\n",
    "    spectrogramx = tf.squeeze(spectrogramx)\n",
    "    inverse_stftx5 = tf.signal.inverse_stft(spectrogramx, 512, 128)\n",
    "    inverse_stftx5 = tf.squeeze(inverse_stftx5)\n",
    "\n",
    "    spectrogramx = tf.squeeze(sound3)\n",
    "    inverse_stftx6 = tf.signal.inverse_stft(spectrogramx, 512, 128)\n",
    "    inverse_stftx6 = tf.squeeze(inverse_stftx6)\n",
    "\n",
    "    magComplex = predictedOutput3[:, :, :, 0]\n",
    "    magComplex = tf.cast(magComplex, tf.complex64)\n",
    "    phaseComplex = predictedOutput3[:, :, :, 1]\n",
    "    phaseComplex = tf.cast(phaseComplex, tf.complex64)\n",
    "    spectrogramx = magComplex * tf.math.exp(1j * phaseComplex)\n",
    "    spectrogramx = tf.squeeze(spectrogramx)\n",
    "    inverse_stftx7 = tf.signal.inverse_stft(spectrogramx, 512, 128)\n",
    "    inverse_stftx7 = tf.squeeze(inverse_stftx7)\n",
    "\n",
    "    # Prepare to process data\n",
    "    string = str(label.numpy())\n",
    "    length = len(string)  \n",
    "    if (string[2:length-1] == \"Mixture\"):\n",
    "        # Save inverse stfts into \"References\" and \"Estimates\" folders\n",
    "        file0 = tf.audio.encode_wav(tf.expand_dims(inverse_stftx0, 1), 16000, name=None)\n",
    "        tf.io.write_file(\"References/file0.wav\", file0, name=None)\n",
    "        file1 = tf.audio.encode_wav(tf.expand_dims(inverse_stftx1, 1), 16000, name=None)\n",
    "        tf.io.write_file(\"Estimates/file0.wav\", file1, name=None)\n",
    "\n",
    "        file2 = tf.audio.encode_wav(tf.expand_dims(inverse_stftx2, 1), 16000, name=None)\n",
    "        tf.io.write_file(\"References/file1.wav\", file2, name=None)\n",
    "        file3 = tf.audio.encode_wav(tf.expand_dims(inverse_stftx3, 1), 16000, name=None)\n",
    "        tf.io.write_file(\"Estimates/file1.wav\", file3, name=None)\n",
    "\n",
    "        file4 = tf.audio.encode_wav(tf.expand_dims(inverse_stftx4, 1), 16000, name=None)\n",
    "        tf.io.write_file(\"References/file2.wav\", file4, name=None)\n",
    "        file5 = tf.audio.encode_wav(tf.expand_dims(inverse_stftx5, 1), 16000, name=None)\n",
    "        tf.io.write_file(\"Estimates/file2.wav\", file5, name=None)\n",
    "\n",
    "        file6 = tf.audio.encode_wav(tf.expand_dims(inverse_stftx6, 1), 16000, name=None)\n",
    "        tf.io.write_file(\"References/file3.wav\", file6, name=None)\n",
    "        file7 = tf.audio.encode_wav(tf.expand_dims(inverse_stftx7, 1), 16000, name=None)\n",
    "        tf.io.write_file(\"Estimates/file3.wav\", file7, name=None)\n",
    "\n",
    "        # Read in saved inverse stfts\n",
    "        fs, ref0 = wavfile.read(\"References/file0.wav\")\n",
    "        fs, est0 = wavfile.read(\"Estimates/file0.wav\")\n",
    "        fs, ref1 = wavfile.read(\"References/file1.wav\")\n",
    "        fs, est1 = wavfile.read(\"Estimates/file1.wav\")\n",
    "        fs, ref2 = wavfile.read(\"References/file2.wav\")\n",
    "        fs, est2 = wavfile.read(\"Estimates/file2.wav\")\n",
    "        fs, ref3 = wavfile.read(\"References/file3.wav\")\n",
    "        fs, est3 = wavfile.read(\"Estimates/file3.wav\")\n",
    "        \n",
    "        # Vacuum Alarm\n",
    "        # Error checking (code utilized from Museval)\n",
    "        if (not ((np.any(np.all(np.sum(ref0, axis=tuple(range(2, ref0.ndim))) == 0, axis=0))\n",
    "           or np.any(np.all(np.sum(est0, axis=tuple(range(2, est0.ndim))) == 0, axis=0)))\n",
    "           or (np.any(np.all(np.sum(ref1, axis=tuple(range(2, ref1.ndim))) == 0, axis=0))\n",
    "           or np.any(np.all(np.sum(est1, axis=tuple(range(2, est1.ndim))) == 0, axis=0))))):\n",
    "            \n",
    "            os.remove(\"References/file2.wav\")\n",
    "            os.remove(\"Estimates/file2.wav\")\n",
    "            os.remove(\"References/file3.wav\")\n",
    "            os.remove(\"Estimates/file3.wav\")\n",
    "            \n",
    "            # Calculate scores, save in \"test.json\"\n",
    "            scores = museval.eval_dir(\"References\", \"Estimates\", \"Outputs\")\n",
    "            scores.save(\"test.json\")\n",
    "\n",
    "            # compute the metrics\n",
    "            f = open('test.json',)\n",
    "\n",
    "            # returns JSON object as\n",
    "            # a dictionary\n",
    "            data = json.load(f)\n",
    "\n",
    "            # Iterating through the json\n",
    "            # list\n",
    "            # Metrics: Vacuum\n",
    "            jsonData = data['targets'][1]['frames'][0]['metrics']\n",
    "            sdrTemp = jsonData.get('SDR')\n",
    "            sirTemp = jsonData.get('SIR')\n",
    "            sarTemp = jsonData.get('SAR')\n",
    "            if (not (math.isnan(sdrTemp))):\n",
    "                sdrV = sdrV + sdrTemp\n",
    "                vcCSDR = vcCSDR + 1\n",
    "            if (not (math.isnan(sirTemp))):\n",
    "                sirV = sirV + sirTemp\n",
    "                vcCSIR = vcCSIR + 1\n",
    "            if (not (math.isnan(sarTemp))):\n",
    "                sarV = sarV + sarTemp\n",
    "                vcCSAR = vcCSAR + 1\n",
    "\n",
    "            # Metrics: Alarm\n",
    "            jsonData = data['targets'][0]['frames'][0]['metrics']\n",
    "            sdrTemp = jsonData.get('SDR')\n",
    "            sirTemp = jsonData.get('SIR')\n",
    "            sarTemp = jsonData.get('SAR')\n",
    "            if (not (math.isnan(sdrTemp))):\n",
    "                sdrA = sdrA + sdrTemp\n",
    "                aCSDR = aCSDR + 1\n",
    "            if (not (math.isnan(sirTemp))):\n",
    "                sirA = sirA + sirTemp\n",
    "                aCSIR = aCSIR + 1\n",
    "            if (not (math.isnan(sarTemp))):\n",
    "                sarA = sarA + sarTemp\n",
    "                aCSAR = aCSAR + 1\n",
    "        \n",
    "        # Vacuum Water\n",
    "        # Error checking\n",
    "        if (not ((np.any(np.all(np.sum(ref0, axis=tuple(range(2, ref0.ndim))) == 0, axis=0))\n",
    "           or np.any(np.all(np.sum(est0, axis=tuple(range(2, est0.ndim))) == 0, axis=0)))\n",
    "           or (np.any(np.all(np.sum(ref2, axis=tuple(range(2, ref2.ndim))) == 0, axis=0))\n",
    "           or np.any(np.all(np.sum(est2, axis=tuple(range(2, est2.ndim))) == 0, axis=0))))):\n",
    "            \n",
    "            os.remove(\"References/file1.wav\")\n",
    "            os.remove(\"Estimates/file1.wav\")\n",
    "            os.remove(\"References/file3.wav\")\n",
    "            os.remove(\"Estimates/file3.wav\")\n",
    "            \n",
    "            # Calculate scores, save in \"test.json\"\n",
    "            scores = museval.eval_dir(\"References\", \"Estimates\", \"Outputs\")\n",
    "            scores.save(\"test.json\")\n",
    "\n",
    "            # compute the metrics\n",
    "            f = open('test.json',)\n",
    "\n",
    "            # returns JSON object as\n",
    "            # a dictionary\n",
    "            data = json.load(f)\n",
    "\n",
    "            # Iterating through the json\n",
    "            # list\n",
    "            # Metrics: Vacuum\n",
    "            jsonData = data['targets'][1]['frames'][0]['metrics']\n",
    "            sdrTemp = jsonData.get('SDR')\n",
    "            sirTemp = jsonData.get('SIR')\n",
    "            sarTemp = jsonData.get('SAR')\n",
    "            if (not (math.isnan(sdrTemp))):\n",
    "                sdrV = sdrV + sdrTemp\n",
    "                vcCSDR = vcCSDR + 1\n",
    "            if (not (math.isnan(sirTemp))):\n",
    "                sirV = sirV + sirTemp\n",
    "                vcCSIR = vcCSIR + 1\n",
    "            if (not (math.isnan(sarTemp))):\n",
    "                sarV = sarV + sarTemp\n",
    "                vcCSAR = vcCSAR + 1\n",
    "\n",
    "            # Metrics: Water\n",
    "            jsonData = data['targets'][0]['frames'][0]['metrics']\n",
    "            sdrTemp = jsonData.get('SDR')\n",
    "            sirTemp = jsonData.get('SIR')\n",
    "            sarTemp = jsonData.get('SAR')\n",
    "            if (not (math.isnan(sdrTemp))):\n",
    "                sdrW = sdrW + sdrTemp\n",
    "                wCSDR = wCSDR + 1\n",
    "            if (not (math.isnan(sirTemp))):\n",
    "                sirW = sirW + sirTemp\n",
    "                wCSIR = wCSIR + 1\n",
    "            if (not (math.isnan(sarTemp))):\n",
    "                sarW = sarW + sarTemp\n",
    "                wCSAR = wCSAR + 1\n",
    "        \n",
    "        # Vacuum Dog\n",
    "        # Error checking\n",
    "        if (not ((np.any(np.all(np.sum(ref0, axis=tuple(range(2, ref0.ndim))) == 0, axis=0))\n",
    "           or np.any(np.all(np.sum(est0, axis=tuple(range(2, est0.ndim))) == 0, axis=0)))\n",
    "           or (np.any(np.all(np.sum(ref3, axis=tuple(range(2, ref3.ndim))) == 0, axis=0))\n",
    "           or np.any(np.all(np.sum(est3, axis=tuple(range(2, est3.ndim))) == 0, axis=0))))):\n",
    "            \n",
    "            os.remove(\"References/file1.wav\")\n",
    "            os.remove(\"Estimates/file1.wav\")\n",
    "            os.remove(\"References/file2.wav\")\n",
    "            os.remove(\"Estimates/file2.wav\")\n",
    "            \n",
    "            # Calculate scores, save in \"test.json\"\n",
    "            scores = museval.eval_dir(\"References\", \"Estimates\", \"Outputs\")\n",
    "            scores.save(\"test.json\")\n",
    "\n",
    "            # compute the metrics\n",
    "            f = open('test.json',)\n",
    "\n",
    "            # returns JSON object as\n",
    "            # a dictionary\n",
    "            data = json.load(f)\n",
    "\n",
    "            # Iterating through the json\n",
    "            # list\n",
    "            # Metrics: Vacuum\n",
    "            jsonData = data['targets'][1]['frames'][0]['metrics']\n",
    "            sdrTemp = jsonData.get('SDR')\n",
    "            sirTemp = jsonData.get('SIR')\n",
    "            sarTemp = jsonData.get('SAR')\n",
    "            if (not (math.isnan(sdrTemp))):\n",
    "                sdrV = sdrV + sdrTemp\n",
    "                vcCSDR = vcCSDR + 1\n",
    "            if (not (math.isnan(sirTemp))):\n",
    "                sirV = sirV + sirTemp\n",
    "                vcCSIR = vcCSIR + 1\n",
    "            if (not (math.isnan(sarTemp))):\n",
    "                sarV = sarV + sarTemp\n",
    "                vcCSAR = vcCSAR + 1\n",
    "\n",
    "            # Metrics: Dog\n",
    "            jsonData = data['targets'][0]['frames'][0]['metrics']\n",
    "            sdrTemp = jsonData.get('SDR')\n",
    "            sirTemp = jsonData.get('SIR')\n",
    "            sarTemp = jsonData.get('SAR')\n",
    "            if (not (math.isnan(sdrTemp))):\n",
    "                sdrD = sdrD + sdrTemp\n",
    "                dCSDR = dCSDR + 1\n",
    "            if (not (math.isnan(sirTemp))):\n",
    "                sirD = sirD + sirTemp\n",
    "                dCSIR = dCSIR + 1\n",
    "            if (not (math.isnan(sarTemp))):\n",
    "                sarD = sarD + sarTemp\n",
    "                dCSAR = dCSAR + 1\n",
    "        \n",
    "        # Alarm Water\n",
    "        # Error checking\n",
    "        if (not ((np.any(np.all(np.sum(ref1, axis=tuple(range(2, ref1.ndim))) == 0, axis=0))\n",
    "           or np.any(np.all(np.sum(est1, axis=tuple(range(2, est1.ndim))) == 0, axis=0)))\n",
    "           or (np.any(np.all(np.sum(ref2, axis=tuple(range(2, ref2.ndim))) == 0, axis=0))\n",
    "           or np.any(np.all(np.sum(est2, axis=tuple(range(2, est2.ndim))) == 0, axis=0))))):\n",
    "            \n",
    "            os.remove(\"References/file0.wav\")\n",
    "            os.remove(\"Estimates/file0.wav\")\n",
    "            os.remove(\"References/file3.wav\")\n",
    "            os.remove(\"Estimates/file3.wav\")\n",
    "            \n",
    "            # Calculate scores, save in \"test.json\"\n",
    "            scores = museval.eval_dir(\"References\", \"Estimates\", \"Outputs\")\n",
    "            scores.save(\"test.json\")\n",
    "\n",
    "            # compute the metrics\n",
    "            f = open('test.json',)\n",
    "\n",
    "            # returns JSON object as\n",
    "            # a dictionary\n",
    "            data = json.load(f)\n",
    "\n",
    "            # Iterating through the json\n",
    "            # list\n",
    "            # Metrics: Alarm\n",
    "            jsonData = data['targets'][1]['frames'][0]['metrics']\n",
    "            sdrTemp = jsonData.get('SDR')\n",
    "            sirTemp = jsonData.get('SIR')\n",
    "            sarTemp = jsonData.get('SAR')\n",
    "            if (not (math.isnan(sdrTemp))):\n",
    "                sdrA = sdrA + sdrTemp\n",
    "                aCSDR = aCSDR + 1\n",
    "            if (not (math.isnan(sirTemp))):\n",
    "                sirA = sirA + sirTemp\n",
    "                aCSIR = aCSIR + 1\n",
    "            if (not (math.isnan(sarTemp))):\n",
    "                sarA = sarA + sarTemp\n",
    "                aCSAR = aCSAR + 1\n",
    "\n",
    "            # Metrics: Water\n",
    "            jsonData = data['targets'][0]['frames'][0]['metrics']\n",
    "            sdrTemp = jsonData.get('SDR')\n",
    "            sirTemp = jsonData.get('SIR')\n",
    "            sarTemp = jsonData.get('SAR')\n",
    "            if (not (math.isnan(sdrTemp))):\n",
    "                sdrW = sdrW + sdrTemp\n",
    "                wCSDR = wCSDR + 1\n",
    "            if (not (math.isnan(sirTemp))):\n",
    "                sirW = sirW + sirTemp\n",
    "                wCSIR = wCSIR + 1\n",
    "            if (not (math.isnan(sarTemp))):\n",
    "                sarW = sarW + sarTemp\n",
    "                wCSAR = wCSAR + 1\n",
    "        \n",
    "        # Alarm Dog\n",
    "        # Error checking\n",
    "        if (not ((np.any(np.all(np.sum(ref1, axis=tuple(range(2, ref1.ndim))) == 0, axis=0))\n",
    "           or np.any(np.all(np.sum(est1, axis=tuple(range(2, est1.ndim))) == 0, axis=0)))\n",
    "           or (np.any(np.all(np.sum(ref3, axis=tuple(range(2, ref3.ndim))) == 0, axis=0))\n",
    "           or np.any(np.all(np.sum(est3, axis=tuple(range(2, est3.ndim))) == 0, axis=0))))):\n",
    "            \n",
    "            os.remove(\"References/file0.wav\")\n",
    "            os.remove(\"Estimates/file0.wav\")\n",
    "            os.remove(\"References/file2.wav\")\n",
    "            os.remove(\"Estimates/file2.wav\")\n",
    "            \n",
    "            # Calculate scores, save in \"test.json\"\n",
    "            scores = museval.eval_dir(\"References\", \"Estimates\", \"Outputs\")\n",
    "            scores.save(\"test.json\")\n",
    "\n",
    "            # compute the metrics\n",
    "            f = open('test.json',)\n",
    "\n",
    "            # returns JSON object as\n",
    "            # a dictionary\n",
    "            data = json.load(f)\n",
    "\n",
    "            # Iterating through the json\n",
    "            # list\n",
    "            # Metrics: Alarm\n",
    "            jsonData = data['targets'][1]['frames'][0]['metrics']\n",
    "            sdrTemp = jsonData.get('SDR')\n",
    "            sirTemp = jsonData.get('SIR')\n",
    "            sarTemp = jsonData.get('SAR')\n",
    "            if (not (math.isnan(sdrTemp))):\n",
    "                sdrA = sdrA + sdrTemp\n",
    "                aCSDR = aCSDR + 1\n",
    "            if (not (math.isnan(sirTemp))):\n",
    "                sirA = sirA + sirTemp\n",
    "                aCSIR = aCSIR + 1\n",
    "            if (not (math.isnan(sarTemp))):\n",
    "                sarA = sarA + sarTemp\n",
    "                aCSAR = aCSAR + 1\n",
    "\n",
    "            # Metrics: Dog\n",
    "            jsonData = data['targets'][0]['frames'][0]['metrics']\n",
    "            sdrTemp = jsonData.get('SDR')\n",
    "            sirTemp = jsonData.get('SIR')\n",
    "            sarTemp = jsonData.get('SAR')\n",
    "            if (not (math.isnan(sdrTemp))):\n",
    "                sdrD = sdrD + sdrTemp\n",
    "                dCSDR = dCSDR + 1\n",
    "            if (not (math.isnan(sirTemp))):\n",
    "                sirD = sirD + sirTemp\n",
    "                dCSIR = dCSIR + 1\n",
    "            if (not (math.isnan(sarTemp))):\n",
    "                sarD = sarD + sarTemp\n",
    "                dCSAR = dCSAR + 1\n",
    "            \n",
    "        \n",
    "        # Water dog\n",
    "        # Error checking\n",
    "        if (not ((np.any(np.all(np.sum(ref2, axis=tuple(range(2, ref2.ndim))) == 0, axis=0))\n",
    "           or np.any(np.all(np.sum(est2, axis=tuple(range(2, est2.ndim))) == 0, axis=0)))\n",
    "           or (np.any(np.all(np.sum(ref3, axis=tuple(range(2, ref3.ndim))) == 0, axis=0))\n",
    "           or np.any(np.all(np.sum(est3, axis=tuple(range(2, est3.ndim))) == 0, axis=0))))):\n",
    "            \n",
    "            os.remove(\"References/file0.wav\")\n",
    "            os.remove(\"Estimates/file0.wav\")\n",
    "            os.remove(\"References/file1.wav\")\n",
    "            os.remove(\"Estimates/file1.wav\")\n",
    "            \n",
    "            # Calculate scores, save in \"test.json\"\n",
    "            scores = museval.eval_dir(\"References\", \"Estimates\", \"Outputs\")\n",
    "            scores.save(\"test.json\")\n",
    "\n",
    "            # compute the metrics\n",
    "            f = open('test.json',)\n",
    "\n",
    "            # returns JSON object as\n",
    "            # a dictionary\n",
    "            data = json.load(f)\n",
    "\n",
    "            # Iterating through the json\n",
    "            # list\n",
    "            # Metrics: Water\n",
    "            jsonData = data['targets'][1]['frames'][0]['metrics']\n",
    "            sdrTemp = jsonData.get('SDR')\n",
    "            sirTemp = jsonData.get('SIR')\n",
    "            sarTemp = jsonData.get('SAR')\n",
    "            if (not (math.isnan(sdrTemp))):\n",
    "                sdrW = sdrW + sdrTemp\n",
    "                wCSDR = wCSDR + 1\n",
    "            if (not (math.isnan(sirTemp))):\n",
    "                sirW = sirW + sirTemp\n",
    "                wCSIR = wCSIR + 1\n",
    "            if (not (math.isnan(sarTemp))):\n",
    "                sarW = sarW + sarTemp\n",
    "                wCSAR = wCSAR + 1\n",
    "\n",
    "            # Metrics: Dog\n",
    "            jsonData = data['targets'][0]['frames'][0]['metrics']\n",
    "            sdrTemp = jsonData.get('SDR')\n",
    "            sirTemp = jsonData.get('SIR')\n",
    "            sarTemp = jsonData.get('SAR')\n",
    "            if (not (math.isnan(sdrTemp))):\n",
    "                sdrD = sdrD + sdrTemp\n",
    "                dCSDR = dCSDR + 1\n",
    "            if (not (math.isnan(sirTemp))):\n",
    "                sirD = sirD + sirTemp\n",
    "                dCSIR = dCSIR + 1\n",
    "            if (not (math.isnan(sarTemp))):\n",
    "                sarD = sarD + sarTemp\n",
    "                dCSAR = dCSAR + 1\n",
    "    \n",
    "    # Delete files in \"References\" and \"Estimates\" folder for next interation\n",
    "    files = glob.glob('Estimates/*.wav', recursive=True)\n",
    "    for f in files:\n",
    "        try:\n",
    "            os.remove(f)\n",
    "        except OSError as e:\n",
    "            print(\"Error: %s : %s\" % (f, e.strerror))\n",
    "    files = glob.glob('References/*.wav', recursive=True)\n",
    "    for f in files:\n",
    "        try:\n",
    "            os.remove(f)\n",
    "        except OSError as e:\n",
    "            print(\"Error: %s : %s\" % (f, e.strerror))\n",
    "\n",
    "# Print out results\n",
    "vcSDRAvg = sdrV / vcCSDR\n",
    "vcSIRAvg = sirV / vcCSIR\n",
    "vcSARAvg = sarV / vcCSAR\n",
    "aSDRAvg = sdrA / aCSDR\n",
    "aSIRAvg = sirA / aCSIR\n",
    "aSARAvg = sarA / aCSAR\n",
    "wSDRAvg = sdrW / wCSDR\n",
    "wSIRAvg = sirW / wCSIR\n",
    "wSARAvg = sarW / wCSAR\n",
    "dSDRAvg = sdrD / dCSDR\n",
    "dSIRAvg = sirD / dCSIR\n",
    "dSARAvg = sarD / dCSAR\n",
    "print(\"vcSDRAvg: \", vcSDRAvg)\n",
    "print(\"vcSIRAvg: \", vcSIRAvg)\n",
    "print(\"vcSARAvg: \", vcSARAvg)\n",
    "print(\"aSDRAvg: \", aSDRAvg)\n",
    "print(\"aSIRAvg: \", aSIRAvg)\n",
    "print(\"aSARAvg: \", aSARAvg)\n",
    "print(\"wSDRAvg: \", wSDRAvg)\n",
    "print(\"wSIRAvg: \", wSIRAvg)\n",
    "print(\"wSARAvg: \", wSARAvg)\n",
    "print(\"dSDRAvg: \", dSDRAvg)\n",
    "print(\"dSIRAvg: \", dSIRAvg)\n",
    "print(\"dSARAvg: \", dSARAvg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of VAWDDesed.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
